{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3628f23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import argparse\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import torch.backends.cudnn as cudnn\n",
    "import scipy.io as sio\n",
    "from scipy.io import savemat\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "from vit_pytorch import ViT\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics, preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import numpy as np\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1098f8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import collections\n",
    "import math\n",
    "import time\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torchsummary import summary\n",
    "import geniter\n",
    "import record\n",
    "import Utils\n",
    "import gc\n",
    "\n",
    "from thop import profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b052bc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAM_DATASET = 'UP'  # UP,IN,SV, KSC\n",
    "PARAM_EPOCH = 50\n",
    "PARAM_ITER = 1\n",
    "PATCH_SIZE = 5\n",
    "PARAM_VAL = 0.77\n",
    "mode='DEN-1'\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "cross_attn_depth=1\n",
    "ssf_enc_depth=1\n",
    "\n",
    "\n",
    "P_dim = 128\n",
    "P_dim_head=64\n",
    "P_mlp_dim = 64\n",
    "P_depth = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e099ada4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "419dc7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = [1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341]\n",
    "dataset = PARAM_DATASET \n",
    "Dataset = dataset.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ea5db66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(Dataset, split=0.95):\n",
    "    data_path = './../data/'\n",
    "    if Dataset == 'IN':\n",
    "        mat_data = sio.loadmat(data_path + 'Indian_pines_corrected.mat')\n",
    "        mat_gt = sio.loadmat(data_path + 'Indian_pines_gt.mat')\n",
    "        data_hsi = mat_data['indian_pines_corrected']\n",
    "        gt_hsi = mat_gt['indian_pines_gt']\n",
    "        K = 200\n",
    "        TOTAL_SIZE = 10249\n",
    "        VALIDATION_SPLIT = split\n",
    "        TRAIN_SIZE = math.ceil(TOTAL_SIZE * VALIDATION_SPLIT)\n",
    "\n",
    "    if Dataset == 'UP':\n",
    "        uPavia = sio.loadmat(data_path + 'PaviaU.mat')\n",
    "        gt_uPavia = sio.loadmat(data_path + 'PaviaU_gt.mat')\n",
    "        data_hsi = uPavia['paviaU']\n",
    "        gt_hsi = gt_uPavia['paviaU_gt']\n",
    "        K = 103\n",
    "        TOTAL_SIZE = 42776\n",
    "        VALIDATION_SPLIT = split\n",
    "        TRAIN_SIZE = math.ceil(TOTAL_SIZE * VALIDATION_SPLIT)\n",
    "\n",
    "    if Dataset == 'SV':\n",
    "        SV = sio.loadmat(data_path + 'Salinas_corrected.mat')\n",
    "        gt_SV = sio.loadmat(data_path + 'Salinas_gt.mat')\n",
    "        data_hsi = SV['salinas_corrected']\n",
    "        gt_hsi = gt_SV['salinas_gt']\n",
    "        K = data_hsi.shape[2]\n",
    "        TOTAL_SIZE = 54129\n",
    "        VALIDATION_SPLIT = split\n",
    "        TRAIN_SIZE = math.ceil(TOTAL_SIZE * VALIDATION_SPLIT)\n",
    "\n",
    "    shapeor = data_hsi.shape\n",
    "    data_hsi = data_hsi.reshape(-1, data_hsi.shape[-1])\n",
    "    data_hsi = PCA(n_components=K).fit_transform(data_hsi)\n",
    "    shapeor = np.array(shapeor)\n",
    "    shapeor[-1] = K\n",
    "    data_hsi = data_hsi.reshape(shapeor)\n",
    "\n",
    "    return data_hsi, gt_hsi, TOTAL_SIZE, TRAIN_SIZE, VALIDATION_SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e231d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_hsi, gt_hsi, TOTAL_SIZE, TRAIN_SIZE, VALIDATION_SPLIT = load_dataset(\n",
    "    Dataset, PARAM_VAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9eb21ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_x, image_y, BAND = data_hsi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dad1d1e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(207400, 103)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data_hsi.reshape(\n",
    "    np.prod(data_hsi.shape[:2]), np.prod(data_hsi.shape[2:]))\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99d8eb6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(610, 340)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_hsi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42811dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = gt_hsi.reshape(np.prod(gt_hsi.shape[:2]), )\n",
    "gt.shape\n",
    "CLASSES_NUM = max(gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8dde8570",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATCH_LENGTH = PATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e4a161d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows = 2 * PATCH_LENGTH + 1\n",
    "img_cols = 2 * PATCH_LENGTH + 1\n",
    "img_channels = data_hsi.shape[2]\n",
    "INPUT_DIMENSION = data_hsi.shape[2]\n",
    "ALL_SIZE = data_hsi.shape[0] * data_hsi.shape[1]\n",
    "VAL_SIZE = int(TRAIN_SIZE)\n",
    "TEST_SIZE = TOTAL_SIZE - TRAIN_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bcdc17fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = preprocessing.scale(data)\n",
    "data_ = data.reshape(data_hsi.shape[0], data_hsi.shape[1], data_hsi.shape[2])\n",
    "whole_data = data_\n",
    "padded_data = np.lib.pad(\n",
    "    whole_data, ((PATCH_LENGTH, PATCH_LENGTH), (PATCH_LENGTH, PATCH_LENGTH),\n",
    "                 (0, 0)),\n",
    "    'constant',\n",
    "    constant_values=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18f119f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(proportion, ground_truth):\n",
    "    train = {}\n",
    "    test = {}\n",
    "    labels_loc = {}\n",
    "    m = max(ground_truth)\n",
    "    for i in range(m):\n",
    "        indexes = [\n",
    "            j for j, x in enumerate(ground_truth.ravel().tolist())\n",
    "            if x == i + 1\n",
    "        ]\n",
    "        np.random.shuffle(indexes)\n",
    "        labels_loc[i] = indexes\n",
    "        if proportion != 1:\n",
    "            nb_val = max(int((1 - proportion) * len(indexes)), 3)\n",
    "        else:\n",
    "            nb_val = 0\n",
    "        train[i] = indexes[:nb_val]\n",
    "        test[i] = indexes[nb_val:]\n",
    "    train_indexes = []\n",
    "    test_indexes = []\n",
    "    for i in range(m):\n",
    "        train_indexes += train[i]\n",
    "        test_indexes += test[i]\n",
    "    np.random.shuffle(train_indexes)\n",
    "    np.random.shuffle(test_indexes)\n",
    "    return train_indexes, test_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17663dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Selecting Small Pieces from the Original Cube Data-----\n",
      "Train size:  (9833, 11, 11, 103)\n"
     ]
    }
   ],
   "source": [
    "index_iter=0\n",
    "np.random.seed(seeds[index_iter])\n",
    "train_indices, test_indices = sampling(VALIDATION_SPLIT, gt)\n",
    "_, total_indices = sampling(1, gt)\n",
    "\n",
    "TRAIN_SIZE = len(train_indices)\n",
    "TEST_SIZE = TOTAL_SIZE - TRAIN_SIZE\n",
    "VAL_SIZE = int(TRAIN_SIZE)\n",
    "\n",
    "print('-----Selecting Small Pieces from the Original Cube Data-----')\n",
    "x_train,y_train, x_val,y_val, x_test,y_test, all_data, gt_all = geniter.generate_iter(\n",
    "        TRAIN_SIZE, train_indices, TEST_SIZE, test_indices, TOTAL_SIZE,\n",
    "        total_indices, VAL_SIZE, whole_data, PATCH_LENGTH, padded_data,\n",
    "        INPUT_DIMENSION, 32, gt)  #batchsize in 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "924cba18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#band_patch=1\n",
    "band=x_train.shape[-1]\n",
    "patch=x_train.shape[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a6ed803",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ViT(\n",
    "    image_size = patch,\n",
    "    num_patches = band,\n",
    "    num_classes = CLASSES_NUM,\n",
    "    dim = P_dim,\n",
    "    dim_head=P_dim_head,\n",
    "    mlp_dim = P_mlp_dim,\n",
    "    depth = P_depth,\n",
    "    heads = 4,\n",
    "    dropout = 0.1,\n",
    "    emb_dropout = 0.1,\n",
    "    mode = mode,\n",
    "    cross_attn_depth = cross_attn_depth, \n",
    "    ssf_enc_depth = ssf_enc_depth\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "999b2e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.normalization.LayerNorm'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "flops:  182149632.0 params:  1778995.0\n",
      "flops: 182.15 M, params: 1.78 M\n"
     ]
    }
   ],
   "source": [
    "dummy_input = torch.randn(1,patch,patch,band)\n",
    "flops, params = profile(model, (dummy_input,))\n",
    "print('flops: ', flops, 'params: ', params)\n",
    "print('flops: %.2f M, params: %.2f M' % (flops / 1000000.0, params / 1000000.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f124df3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net,\n",
    "          train_iter,\n",
    "          valida_iter,\n",
    "          loss,\n",
    "          optimizer,\n",
    "          device,\n",
    "          epochs,\n",
    "          early_stopping=False,\n",
    "          early_num=20):\n",
    "    loss_list = [100]\n",
    "    early_epoch = 0\n",
    "\n",
    "    net = net.to(device)\n",
    "    print(\"training on \", device)\n",
    "    start = time.time()\n",
    "    train_loss_list = []\n",
    "    valida_loss_list = []\n",
    "    train_acc_list = []\n",
    "    valida_acc_list = []\n",
    "    for epoch in range(epochs):\n",
    "        train_acc_sum, n = 0.0, 0\n",
    "        time_epoch = time.time()\n",
    "        lr_adjust = torch.optim.lr_scheduler.StepLR(\n",
    "            optimizer, step_size=PARAM_EPOCH//10, gamma=0.9)\n",
    "        for X, y in train_iter:\n",
    "\n",
    "            batch_count, train_l_sum = 0, 0\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y.long())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            train_l_sum += l.cpu().item()\n",
    "            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().cpu().item()\n",
    "            n += y.shape[0]\n",
    "            batch_count += 1\n",
    "        lr_adjust.step()\n",
    "        valida_acc, valida_loss = record.evaluate_accuracy(\n",
    "            valida_iter, net, loss, device)\n",
    "        loss_list.append(valida_loss)\n",
    "\n",
    "        train_loss_list.append(train_l_sum)  # / batch_count)\n",
    "        train_acc_list.append(train_acc_sum / n)\n",
    "        valida_loss_list.append(valida_loss)\n",
    "        valida_acc_list.append(valida_acc)\n",
    "\n",
    "        print(\n",
    "            'epoch %d, train loss %.6f, train acc %.3f, valida loss %.6f, valida acc %.3f, time %.1f sec'\n",
    "            % (epoch + 1, train_l_sum / batch_count, train_acc_sum / n,\n",
    "               valida_loss, valida_acc, time.time() - time_epoch))\n",
    "\n",
    "        PATH = \"./net_DBA.pt\"\n",
    "\n",
    "        if early_stopping and loss_list[-2] < loss_list[-1]:\n",
    "            if early_epoch == 0:\n",
    "                torch.save(net.state_dict(), PATH)\n",
    "            early_epoch += 1\n",
    "            loss_list[-1] = loss_list[-2]\n",
    "            if early_epoch == early_num:\n",
    "                net.load_state_dict(torch.load(PATH))\n",
    "                break\n",
    "        else:\n",
    "            early_epoch = 0\n",
    "\n",
    "    print('epoch %d, loss %.4f, train acc %.3f, time %.1f sec'\n",
    "          % (epoch + 1, train_l_sum / batch_count, train_acc_sum / n,\n",
    "             time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa0e9d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99d02140",
   "metadata": {},
   "outputs": [],
   "source": [
    "ITER = PARAM_ITER\n",
    "KAPPA = []\n",
    "OA = []\n",
    "AA = []\n",
    "TRAINING_TIME = []\n",
    "TESTING_TIME = []\n",
    "ELEMENT_ACC = np.zeros((ITER, CLASSES_NUM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36ca3f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "631"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del data_hsi,data,data_\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "31a49a3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 0\n",
      "-----Selecting Small Pieces from the Original Cube Data-----\n",
      "Train size:  (9833, 11, 11, 103)\n",
      "training on  cuda\n",
      "epoch 1, train loss 0.490677, train acc 0.768, valida loss 0.102546, valida acc 0.825, time 19.8 sec\n",
      "epoch 2, train loss 0.082561, train acc 0.890, valida loss 0.141118, valida acc 0.905, time 22.3 sec\n",
      "epoch 3, train loss 0.070157, train acc 0.917, valida loss 0.067733, valida acc 0.945, time 22.1 sec\n",
      "epoch 4, train loss 0.046796, train acc 0.922, valida loss 0.092487, valida acc 0.930, time 22.1 sec\n",
      "epoch 5, train loss 0.077367, train acc 0.929, valida loss 0.047455, valida acc 0.930, time 22.1 sec\n",
      "epoch 6, train loss 0.671118, train acc 0.920, valida loss 0.123710, valida acc 0.926, time 22.3 sec\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 80\u001b[0m\n\u001b[1;32m     73\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(\n\u001b[1;32m     74\u001b[0m     model\u001b[38;5;241m.\u001b[39mparameters(),\n\u001b[1;32m     75\u001b[0m     lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m,\n\u001b[1;32m     76\u001b[0m     weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     79\u001b[0m tic1 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 80\u001b[0m train(\n\u001b[1;32m     81\u001b[0m         model,\n\u001b[1;32m     82\u001b[0m         label_train_loader,\n\u001b[1;32m     83\u001b[0m         label_val_loader,\n\u001b[1;32m     84\u001b[0m         loss,\n\u001b[1;32m     85\u001b[0m         optimizer,\n\u001b[1;32m     86\u001b[0m         device,\n\u001b[1;32m     87\u001b[0m         epochs\u001b[38;5;241m=\u001b[39mPARAM_EPOCH)\n\u001b[1;32m     88\u001b[0m toc1 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     92\u001b[0m pred_test \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[0;32mIn[20], line 41\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(net, train_iter, valida_iter, loss, optimizer, device, epochs, early_stopping, early_num)\u001b[0m\n\u001b[1;32m     39\u001b[0m     batch_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     40\u001b[0m lr_adjust\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 41\u001b[0m valida_acc, valida_loss \u001b[38;5;241m=\u001b[39m record\u001b[38;5;241m.\u001b[39mevaluate_accuracy(\n\u001b[1;32m     42\u001b[0m     valida_iter, net, loss, device)\n\u001b[1;32m     43\u001b[0m loss_list\u001b[38;5;241m.\u001b[39mappend(valida_loss)\n\u001b[1;32m     45\u001b[0m train_loss_list\u001b[38;5;241m.\u001b[39mappend(train_l_sum)  \u001b[38;5;66;03m# / batch_count)\u001b[39;00m\n",
      "File \u001b[0;32m~/AYUSH_RANJAN/CS2DT/record.py:14\u001b[0m, in \u001b[0;36mevaluate_accuracy\u001b[0;34m(data_iter, net, loss, device)\u001b[0m\n\u001b[1;32m     12\u001b[0m y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     13\u001b[0m net\u001b[38;5;241m.\u001b[39meval() \n\u001b[0;32m---> 14\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m net(X)\n\u001b[1;32m     15\u001b[0m l \u001b[38;5;241m=\u001b[39m loss(y_hat, y\u001b[38;5;241m.\u001b[39mlong())\n\u001b[1;32m     16\u001b[0m acc_sum \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (y_hat\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m y\u001b[38;5;241m.\u001b[39mto(device))\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/AYUSH_RANJAN/CS2DT/vit_pytorch.py:261\u001b[0m, in \u001b[0;36mViT.forward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m    259\u001b[0m xl\u001b[38;5;241m=\u001b[39mx2\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ssf_transformer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssf_transformers:\n\u001b[0;32m--> 261\u001b[0m     xs, xl \u001b[38;5;241m=\u001b[39m ssf_transformer(xs, xl)\n\u001b[1;32m    262\u001b[0m xs \u001b[38;5;241m=\u001b[39m xs\u001b[38;5;241m.\u001b[39mmean(dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool1 \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m xs[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    263\u001b[0m xl \u001b[38;5;241m=\u001b[39m xl\u001b[38;5;241m.\u001b[39mmean(dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool2 \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m xl[:, \u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/AYUSH_RANJAN/CS2DT/vit_pytorch.py:143\u001b[0m, in \u001b[0;36mMultiScaleTransformerEncoder.forward\u001b[0;34m(self, xs, xl, mask)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, xs, xl,mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 143\u001b[0m     xs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer_enc_small(xs,mask)\n\u001b[1;32m    144\u001b[0m     xl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer_enc_large(xl,mask)\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f_sl, g_ls, cross_attn_s, f_ls, g_sl, cross_attn_l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcross_attn_layers:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/AYUSH_RANJAN/CS2DT/vit_pytorch.py:113\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m    111\u001b[0m         x\u001b[38;5;241m=\u001b[39m(torch\u001b[38;5;241m.\u001b[39mcat([x, last_output[nl\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mj]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m3\u001b[39m)], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m))\n\u001b[1;32m    112\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskipcat[nl\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m](x)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m--> 113\u001b[0m x \u001b[38;5;241m=\u001b[39m attn(x, mask \u001b[38;5;241m=\u001b[39m mask)\n\u001b[1;32m    114\u001b[0m x \u001b[38;5;241m=\u001b[39m ff(x)\n\u001b[1;32m    115\u001b[0m nl \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/AYUSH_RANJAN/CS2DT/vit_pytorch.py:12\u001b[0m, in \u001b[0;36mResidual.forward\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn(x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m+\u001b[39m x\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/AYUSH_RANJAN/CS2DT/vit_pytorch.py:20\u001b[0m, in \u001b[0;36mPreNorm.forward\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(x), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/AYUSH_RANJAN/CS2DT/vit_pytorch.py:74\u001b[0m, in \u001b[0;36mAttention.forward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# cat all output -> [b, n, head_num*head_dim]\u001b[39;00m\n\u001b[1;32m     73\u001b[0m out \u001b[38;5;241m=\u001b[39m rearrange(out, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb h n d -> b n (h d)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 74\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_out(out)\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for index_iter in range(ITER):\n",
    "    print('iter:', index_iter)\n",
    "    \n",
    "    np.random.seed(seeds[index_iter])\n",
    "    train_indices, test_indices = sampling(VALIDATION_SPLIT, gt)\n",
    "    _, total_indices = sampling(1, gt)\n",
    "\n",
    "    TRAIN_SIZE = len(train_indices)\n",
    "    TEST_SIZE = TOTAL_SIZE - TRAIN_SIZE\n",
    "    VAL_SIZE = int(TRAIN_SIZE)\n",
    "\n",
    "    print('-----Selecting Small Pieces from the Original Cube Data-----')\n",
    "    x_train,y_train, x_val,y_val, x_test,y_test, all_data, gt_all = geniter.generate_iter(\n",
    "            TRAIN_SIZE, train_indices, TEST_SIZE, test_indices, TOTAL_SIZE,\n",
    "            total_indices, VAL_SIZE, whole_data, PATCH_LENGTH, padded_data,\n",
    "            INPUT_DIMENSION, 32, gt) \n",
    "\n",
    "    del all_data,gt_all\n",
    "    gc.collect()\n",
    "    \n",
    "    band=x_train.shape[-1]\n",
    "    patch=x_train.shape[-2]\n",
    "    \n",
    "    \n",
    "    x_train=torch.from_numpy(x_train).type(torch.FloatTensor) \n",
    "    y_train=torch.from_numpy(y_train).type(torch.FloatTensor) \n",
    "    Label_train=Data.TensorDataset(x_train,y_train)\n",
    "    \n",
    "    del x_train,y_train\n",
    "    gc.collect()\n",
    "    \n",
    "    x_test=torch.from_numpy(x_test).type(torch.FloatTensor)\n",
    "    y_test=torch.from_numpy(y_test).type(torch.FloatTensor) \n",
    "    Label_test=Data.TensorDataset(x_test,y_test)\n",
    "    \n",
    "    del x_test,y_test\n",
    "    gc.collect()\n",
    "    \n",
    "    x_val=torch.from_numpy(x_val).type(torch.FloatTensor)\n",
    "    y_val=torch.from_numpy(y_val).type(torch.FloatTensor)\n",
    "    Label_val=Data.TensorDataset(x_val,y_val)\n",
    "    \n",
    "    del x_val,y_val\n",
    "    gc.collect()\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    label_train_loader=Data.DataLoader(Label_train,batch_size=32,shuffle=True)\n",
    "    label_test_loader=Data.DataLoader(Label_test,batch_size=32,shuffle=False)\n",
    "    label_val_loader=Data.DataLoader(Label_val,batch_size=32,shuffle=False)\n",
    "    \n",
    "    del Label_train,Label_test,Label_val\n",
    "    gc.collect()\n",
    "    model = ViT(\n",
    "    image_size = patch,\n",
    "    num_patches = band,\n",
    "    num_classes = CLASSES_NUM,\n",
    "    dim = P_dim,\n",
    "    dim_head=P_dim_head,\n",
    "    mlp_dim = P_mlp_dim,\n",
    "    depth = P_depth,\n",
    "    heads = 4,\n",
    "    dropout = 0.1,\n",
    "    emb_dropout = 0.1,\n",
    "    mode = mode,\n",
    "    cross_attn_depth = cross_attn_depth, \n",
    "    ssf_enc_depth = ssf_enc_depth\n",
    ")\n",
    "    model = model.cuda()\n",
    "    model.train()\n",
    "    \n",
    "    optimizer = optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=0.01,\n",
    "        weight_decay=0)\n",
    "\n",
    "    \n",
    "    tic1 = time.time()\n",
    "    train(\n",
    "            model,\n",
    "            label_train_loader,\n",
    "            label_val_loader,\n",
    "            loss,\n",
    "            optimizer,\n",
    "            device,\n",
    "            epochs=PARAM_EPOCH)\n",
    "    toc1 = time.time()\n",
    "    \n",
    "    \n",
    "    \n",
    "    pred_test = []\n",
    "    tic2 = time.time()\n",
    "    with torch.no_grad():\n",
    "        for X, y in label_test_loader:\n",
    "            X = X.to(device)\n",
    "            model.eval()\n",
    "            y_hat = model(X)\n",
    "            pred_test.extend(np.array(model(X).cpu().argmax(axis=1)))\n",
    "    toc2 = time.time()\n",
    "    collections.Counter(pred_test)\n",
    "    gt_test = gt[test_indices] - 1\n",
    "\n",
    "    overall_acc = metrics.accuracy_score(pred_test, gt_test[:-VAL_SIZE])\n",
    "    confusion_matrix = metrics.confusion_matrix(pred_test, gt_test[:-VAL_SIZE])\n",
    "    each_acc, average_acc = record.aa_and_each_accuracy(confusion_matrix)\n",
    "    kappa = metrics.cohen_kappa_score(pred_test, gt_test[:-VAL_SIZE])\n",
    "    \n",
    "    KAPPA.append(kappa)\n",
    "    OA.append(overall_acc)\n",
    "    AA.append(average_acc)\n",
    "    TRAINING_TIME.append(toc1 - tic1)\n",
    "    TESTING_TIME.append(toc2 - tic2)\n",
    "    ELEMENT_ACC[index_iter, :] = each_acc\n",
    "    \n",
    "    del label_train_loader,label_test_loader,label_val_loader\n",
    "    gc.collect()\n",
    "    \n",
    "print(\"--------\" + \" Training Finished-----------\")\n",
    "record.record_output(\n",
    "    OA, AA, KAPPA, ELEMENT_ACC, TRAINING_TIME, TESTING_TIME, flops, params,\n",
    "    './report/' + 'CS2DT'+ Dataset + '_' +str(mode)+'_dep_'+str(P_depth)+'_SSF_'+str(ssf_enc_depth)+'_Cro_'+str(cross_attn_depth)+'_Patch_'+ str(img_rows) + '_' +'spl'\n",
    "    + str(VALIDATION_SPLIT) +'.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea0d4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train, x_val,y_val, x_test,y_test, all_data, gt_all = geniter.generate_iter(\n",
    "            TRAIN_SIZE, train_indices, TEST_SIZE, test_indices, TOTAL_SIZE,\n",
    "            total_indices, VAL_SIZE, whole_data, PATCH_LENGTH, padded_data,\n",
    "            INPUT_DIMENSION, 32, gt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c309635a",
   "metadata": {},
   "outputs": [],
   "source": [
    "del whole_data,padded_data,x_train,y_train, x_val,y_val, x_test,y_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695f5b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all=torch.from_numpy(all_data).type(torch.FloatTensor)\n",
    "y_all=torch.from_numpy(gt_all).type(torch.FloatTensor)\n",
    "Label_all=Data.TensorDataset(x_all,y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5940ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "del x_all,y_all\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e662ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_all_loader=Data.DataLoader(Label_all,batch_size=32,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691525cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Utils.generate_png(\n",
    "    label_all_loader, model, gt_hsi, Dataset, device, total_indices,\n",
    "    './classification_maps/' + 'CS2DT'+ Dataset + '_' +str(mode)+'_dep_'+str(P_depth)+'_SSF_'+str(ssf_enc_depth)+'_Cro_'+str(cross_attn_depth)+'_Patch_'+ str(img_rows) + '_' +'spl'\n",
    "    + str(VALIDATION_SPLIT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475b7002-c27f-47f0-b467-1daf865e8cdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "4f0e2fe85115fd2386557c42e0d23c6fb95dd61fe2d1e647d69acf95e1a29035"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
