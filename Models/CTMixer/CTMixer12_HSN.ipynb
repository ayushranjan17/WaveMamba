{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "615fb01b-d7f5-478f-bb9f-0d411056796d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-12 16:16:50.260701: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-12 16:16:50.288205: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-12 16:16:50.288246: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-12 16:16:50.307450: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-12 16:16:51.275501: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spectral in /home/cvlab/anaconda3/lib/python3.11/site-packages (0.23.1)\n",
      "Requirement already satisfied: numpy in /home/cvlab/anaconda3/lib/python3.11/site-packages (from spectral) (1.23.5)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Conv2D, Conv3D, Flatten, Dense, Reshape, BatchNormalization\n",
    "from keras.layers import Dropout, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras import backend as Kb\n",
    "from keras.layers import Lambda\n",
    "from keras.layers import Activation\n",
    "from keras.layers import add, concatenate\n",
    "from keras.layers import AveragePooling2D\n",
    "from keras.utils import plot_model\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, cohen_kappa_score\n",
    " \n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "from sklearn.decomposition import PCA\n",
    "from operator import truediv\n",
    "\n",
    "\n",
    "from plotly.offline import init_notebook_mode\n",
    " \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import os\n",
    "!pip install spectral\n",
    "import spectral\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2daee46f-b8ad-4d65-873c-b1271d74b849",
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyFA(X, numComponents=75):\n",
    "    newX = np.reshape(X, (-1, X.shape[2]))\n",
    "    fa = FactorAnalysis(n_components=numComponents, random_state=0)\n",
    "    newX = fa.fit_transform(newX)\n",
    "    newX = np.reshape(newX, (X.shape[0],X.shape[1], numComponents))\n",
    "    return newX, fa\n",
    "## GLOBAL VARIABLES\n",
    "dataset = 'HSN'\n",
    "test_ratio = 0.95\n",
    "windowSize = 12\n",
    "def loadData(name):\n",
    "    data_path = os.path.join(os.getcwd(),'data')\n",
    "    if name == 'HSN':\n",
    "        data = sio.loadmat(os.path.join(data_path, '2013_IEEE_GRSS_DF_Contest_CASI_349_1905_144.mat'))['ans']\n",
    "        labels = sio.loadmat(os.path.join(data_path, 'GRSS2013.mat'))['name']\n",
    "    elif name == 'SA':\n",
    "        data = sio.loadmat(os.path.join(data_path, 'Salinas_corrected.mat'))['salinas_corrected']\n",
    "        labels = sio.loadmat(os.path.join(data_path, 'Salinas_gt.mat'))['salinas_gt']\n",
    "    elif name == 'PU':\n",
    "        data = sio.loadmat(os.path.join(data_path, 'PaviaU.mat'))['paviaU']\n",
    "        labels = sio.loadmat(os.path.join(data_path, 'PaviaU_gt.mat'))['paviaU_gt']\n",
    "    \n",
    "    return data, labels\n",
    "def splitTrainTestSet(X, y, testRatio, randomState=345):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testRatio, random_state=randomState,\n",
    "                                                        stratify=y)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "def padWithZeros(X, margin=2):\n",
    "    newX = np.zeros((X.shape[0] + 2 * margin, X.shape[1] + 2* margin, X.shape[2]))\n",
    "    x_offset = margin\n",
    "    y_offset = margin\n",
    "    newX[x_offset:X.shape[0] + x_offset, y_offset:X.shape[1] + y_offset, :] = X\n",
    "    return newX\n",
    "def createImageCubes(X, y, windowSize=8, removeZeroLabels = True):\n",
    "    margin = int((windowSize) / 2)\n",
    "    zeroPaddedX = padWithZeros(X, margin=margin)\n",
    "    # split patches\n",
    "    patchesData = np.zeros((X.shape[0] * X.shape[1], windowSize, windowSize, X.shape[2]))\n",
    "    patchesLabels = np.zeros((X.shape[0] * X.shape[1]))\n",
    "    patchIndex = 0\n",
    "    for r in range(margin, zeroPaddedX.shape[0] - margin):\n",
    "        for c in range(margin, zeroPaddedX.shape[1] - margin):\n",
    "            patch = zeroPaddedX[r - margin:r + margin , c - margin:c + margin ]   \n",
    "            patchesData[patchIndex, :, :, :] = patch\n",
    "            patchesLabels[patchIndex] = y[r-margin, c-margin]\n",
    "            patchIndex = patchIndex + 1\n",
    "    if removeZeroLabels:\n",
    "        patchesData = patchesData[patchesLabels>0,:,:,:]\n",
    "        patchesLabels = patchesLabels[patchesLabels>0]\n",
    "        patchesLabels -= 1\n",
    "    return patchesData, patchesLabels\n",
    "def applyFA(X, numComponents=75):\n",
    "    newX = np.reshape(X, (-1, X.shape[2]))\n",
    "    fa = FactorAnalysis(n_components=numComponents, random_state=0)\n",
    "    newX = fa.fit_transform(newX)\n",
    "    newX = np.reshape(newX, (X.shape[0],X.shape[1], numComponents))\n",
    "    return newX, fa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9376abba-2653-4854-9760-451ba3b14875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((349, 1905, 144), (349, 1905))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = loadData(dataset)\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0aa09b66-dffb-42cb-b2db-113ad8b8f83a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(349, 1905, 25)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#K = X.shape[2]\n",
    "K = 25\n",
    "X,fa = applyFA(X,numComponents=K)\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14b6f9a8-2046-4c3d-acf2-b296d103ab98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15029, 12, 12, 25), (15029,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = createImageCubes(X, y, windowSize=windowSize)\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1628d0e-4da5-41e9-99c6-85c3c91fd9da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((751, 12, 12, 25), (14278, 12, 12, 25), (751,), (14278,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = splitTrainTestSet(X, y, test_ratio)\n",
    "\n",
    "Xtrain.shape, Xtest.shape, ytrain.shape, ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7be6228-b14b-4af0-9a5a-b42afa50f804",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = Xtrain.transpose(0, 3, 1, 2).reshape(751, 1, 25, 12, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3f4a4ee-f1a8-4e03-a769-6b78a5f5d06e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(751, 1, 25, 12, 12)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2b96bc8-9e85-49f8-b6ab-d1407c65ea40",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest = Xtest.transpose(0, 3, 1, 2).reshape(14278, 1, 25, 12, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20e0c85e-9e77-4522-9a5b-76b391c79321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14278, 1, 25, 12, 12)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42580f39-ef7c-41d3-8b06-d701efaea90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape: torch.Size([751, 1, 25, 12, 12])\n",
      "320\n",
      "CTMixer(\n",
      "  639.28 k, 97.198% Params, 91.83 MMac, 99.660% MACs, \n",
      "  (act): ReLU(0, 0.000% Params, 36.86 KMac, 0.040% MACs, inplace=True)\n",
      "  (pad): ReplicationPad3d(0, 0.000% Params, 0.0 Mac, 0.000% MACs, (0, 0, 0, 0, 0, 0))\n",
      "  (conv_1): Conv2d(1.92 k, 0.292% Params, 276.48 KMac, 0.300% MACs, 25, 320, kernel_size=(1, 1), stride=(1, 1), groups=5)\n",
      "  (bn_1): BatchNorm2d(640, 0.097% Params, 92.16 KMac, 0.100% MACs, 320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (res0): Res(\n",
      "    555.94 k, 84.526% Params, 80.05 MMac, 86.876% MACs, \n",
      "    (conv1): Conv2d(184.64 k, 28.073% Params, 26.59 MMac, 28.854% MACs, 320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=5)\n",
      "    (bn1): BatchNorm2d(640, 0.097% Params, 92.16 KMac, 0.100% MACs, 320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(184.64 k, 28.073% Params, 26.59 MMac, 28.854% MACs, 320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=5)\n",
      "    (bn2): BatchNorm2d(640, 0.097% Params, 92.16 KMac, 0.100% MACs, 320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (res2): Res2(\n",
      "      185.38 k, 28.185% Params, 26.69 MMac, 28.969% MACs, \n",
      "      (conv1): Conv2d(92.19 k, 14.017% Params, 13.28 MMac, 14.407% MACs, 320, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, 0.010% Params, 9.22 KMac, 0.010% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(92.48 k, 14.061% Params, 13.32 MMac, 14.452% MACs, 32, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(640, 0.097% Params, 92.16 KMac, 0.100% MACs, 320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (bn1): BatchNorm2d(256, 0.039% Params, 36.86 KMac, 0.040% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv1): Conv2d(8.26 k, 1.255% Params, 1.19 MMac, 1.290% MACs, 128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (bn2): BatchNorm2d(128, 0.019% Params, 18.43 KMac, 0.020% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(640, 0.097% Params, 92.16 KMac, 0.100% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
      "  (bn3): BatchNorm2d(128, 0.019% Params, 18.43 KMac, 0.020% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(8.32 k, 1.265% Params, 1.2 MMac, 1.300% MACs, 64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (patch_embeddings): PatchEmbeddings(\n",
      "    41.09 k, 6.247% Params, 5.92 MMac, 6.421% MACs, \n",
      "    (patchify): Rearrange('b c (h p1) (w p2) -> b (h w) c p1 p2', p1=1, p2=1)\n",
      "    (flatten): Flatten(0, 0.000% Params, 0.0 Mac, 0.000% MACs, start_dim=2, end_dim=-1)\n",
      "    (proj): Linear(41.09 k, 6.247% Params, 5.92 MMac, 6.421% MACs, in_features=320, out_features=128, bias=True)\n",
      "  )\n",
      "  (pos_embeddings): PositionalEmbeddings(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "  (transformer): transformer(\n",
      "    19.78 k, 3.007% Params, 2.9 MMac, 3.150% MACs, \n",
      "    (layers): ModuleList(\n",
      "      (0): ModuleList(\n",
      "        (0): Sequential(\n",
      "          2.05 k, 0.311% Params, 331.78 KMac, 0.360% MACs, \n",
      "          (0): LayerNorm(256, 0.039% Params, 18.43 KMac, 0.020% MACs, (128,), eps=1e-05, elementwise_affine=True)\n",
      "          (1): Attention_Conv(\n",
      "            1.79 k, 0.272% Params, 313.34 KMac, 0.340% MACs, \n",
      "            (attn): Softmax(0, 0.000% Params, 0.0 Mac, 0.000% MACs, dim=-1)\n",
      "            (act): ReLU(0, 0.000% Params, 18.43 KMac, 0.020% MACs, inplace=True)\n",
      "            (bn): BatchNorm2d(256, 0.039% Params, 36.86 KMac, 0.040% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (qkv): Conv2d(768, 0.117% Params, 110.59 KMac, 0.120% MACs, 128, 768, kernel_size=(1, 1), stride=(1, 1), groups=128, bias=False)\n",
      "            (avgpool): AdaptiveAvgPool1d(0, 0.000% Params, 36.86 KMac, 0.040% MACs, output_size=128)\n",
      "            (qs): Conv2d(384, 0.058% Params, 55.3 KMac, 0.060% MACs, 128, 128, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), groups=128, bias=False)\n",
      "            (ks): Conv2d(384, 0.058% Params, 55.3 KMac, 0.060% MACs, 128, 128, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), groups=128, bias=False)\n",
      "          )\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          17.73 k, 2.695% Params, 2.57 MMac, 2.790% MACs, \n",
      "          (0): LayerNorm(256, 0.039% Params, 18.43 KMac, 0.020% MACs, (128,), eps=1e-05, elementwise_affine=True)\n",
      "          (1): FeedForward_Conv(\n",
      "            17.47 k, 2.656% Params, 2.55 MMac, 2.770% MACs, \n",
      "            (conv1): Sequential(\n",
      "              8.45 k, 1.284% Params, 1.23 MMac, 1.340% MACs, \n",
      "              (0): BatchNorm2d(256, 0.039% Params, 36.86 KMac, 0.040% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (1): GELU(0, 0.000% Params, 18.43 KMac, 0.020% MACs, approximate='none')\n",
      "              (2): Conv2d(8.19 k, 1.246% Params, 1.18 MMac, 1.280% MACs, 128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            )\n",
      "            (conv2): Sequential(\n",
      "              704, 0.107% Params, 110.59 KMac, 0.120% MACs, \n",
      "              (0): BatchNorm2d(128, 0.019% Params, 18.43 KMac, 0.020% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (1): GELU(0, 0.000% Params, 9.22 KMac, 0.010% MACs, approximate='none')\n",
      "              (2): Conv2d(576, 0.088% Params, 82.94 KMac, 0.090% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
      "            )\n",
      "            (conv3): Sequential(\n",
      "              8.32 k, 1.265% Params, 1.21 MMac, 1.310% MACs, \n",
      "              (0): BatchNorm2d(128, 0.019% Params, 18.43 KMac, 0.020% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (1): GELU(0, 0.000% Params, 9.22 KMac, 0.010% MACs, approximate='none')\n",
      "              (2): Conv2d(8.19 k, 1.246% Params, 1.18 MMac, 1.280% MACs, 64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.5, inplace=False)\n",
      "  (pool): Pooling(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "  (classifier): Classifier(\n",
      "    2.19 k, 0.333% Params, 2.06 KMac, 0.002% MACs, \n",
      "    (model): Sequential(\n",
      "      2.19 k, 0.333% Params, 2.06 KMac, 0.002% MACs, \n",
      "      (0): LayerNorm(256, 0.039% Params, 128.0 Mac, 0.000% MACs, (128,), eps=1e-05, elementwise_affine=True)\n",
      "      (1): Linear(1.94 k, 0.294% Params, 1.94 KMac, 0.002% MACs, in_features=128, out_features=15, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "MACs: 92.15 MMac\n",
      "Parameters: 657.71 k\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchinfo import summary\n",
    "from ptflops import get_model_complexity_info\n",
    "from transformer import transformer\n",
    "from embeddings import (PatchEmbeddings, CLSToken, PositionalEmbeddings)\n",
    "\n",
    "class Pooling(nn.Module):\n",
    "    def __init__(self, pool: str = \"mean\"):\n",
    "        super().__init__()\n",
    "        if pool not in [\"mean\", \"cls\"]:\n",
    "            raise ValueError(\"pool must be one of {mean, cls}\")\n",
    "\n",
    "        self.pool_fn = self.mean_pool if pool == \"mean\" else self.cls_pool\n",
    "\n",
    "    def mean_pool(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return x.mean(dim=1)\n",
    "\n",
    "    def cls_pool(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return x[:, 0]\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.pool_fn(x)\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, dim: int, num_classes: int):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.LayerNorm(dim),\n",
    "            nn.Linear(in_features=dim, out_features=num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.model(x)\n",
    "\n",
    "class Res2(nn.Module):\n",
    "    def __init__(self, in_channels, inter_channels, kernel_size, padding=0):\n",
    "        super(Res2, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, inter_channels, kernel_size=kernel_size, padding=padding)\n",
    "        self.bn1 = nn.BatchNorm2d(inter_channels)\n",
    "        self.conv2 = nn.Conv2d(inter_channels, in_channels, kernel_size=kernel_size, padding=padding)\n",
    "        self.bn2 = nn.BatchNorm2d(in_channels)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.bn1(self.conv1(X)))\n",
    "        X = self.bn2(self.conv2(X))\n",
    "        return X\n",
    "\n",
    "class Res(nn.Module):\n",
    "    def __init__(self, in_channels, kernel_size, padding, groups_s):\n",
    "        super(Res, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, in_channels, kernel_size=kernel_size, padding=padding, groups=groups_s)\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "        self.conv2 = nn.Conv2d(in_channels, in_channels, kernel_size=kernel_size, padding=padding, groups=groups_s)\n",
    "        self.bn2 = nn.BatchNorm2d(in_channels)\n",
    "        self.res2 = Res2(in_channels, 32, kernel_size=kernel_size, padding=padding)\n",
    "\n",
    "    def forward(self, X):\n",
    "        Y = F.relu(self.bn1(self.conv1(X)))\n",
    "        Y = self.bn2(self.conv2(Y))\n",
    "        Z = self.res2(X)\n",
    "        return F.relu(X + Y + Z)\n",
    "\n",
    "class CTMixer(nn.Module):\n",
    "    def __init__(self, channels, num_classes, image_size, datasetname, num_layers: int=1, num_heads: int=4, \n",
    "                 patch_size: int = 1, emb_dim: int = 128, head_dim = 64, hidden_dim: int = 64, pool: str = \"mean\"):\n",
    "        super().__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.channels = channels\n",
    "        self.image_size = image_size\n",
    "        self.num_patches = (image_size // patch_size) ** 2\n",
    "        self.num_patch = int(math.sqrt(self.num_patches))\n",
    "        self.act = nn.ReLU(inplace=True)\n",
    "        patch_dim = channels * patch_size ** 2\n",
    "\n",
    "        # Conv Preprocessing Module (Ref-SPRN)\n",
    "        if datasetname == 'IndianPines':\n",
    "            groups = 10  # Adjusted groups to match channels\n",
    "            groups_width = 40  # Adjusted width to match groups\n",
    "        elif datasetname == 'PaviaU':\n",
    "            groups = 5\n",
    "            groups_width = 64\n",
    "        elif datasetname == 'Salinas':\n",
    "            groups = 11\n",
    "            groups_width = 37\n",
    "        elif datasetname == 'Houston':\n",
    "            groups = 5\n",
    "            groups_width = 64\n",
    "        else:\n",
    "            groups = 11\n",
    "            groups_width = 37\n",
    "\n",
    "        new_bands = math.ceil(channels/groups) * groups\n",
    "        patch_dim = (groups*groups_width) * patch_size ** 2\n",
    "        pad_size = new_bands - channels\n",
    "        self.pad = nn.ReplicationPad3d((0, 0, 0, 0, 0, pad_size))\n",
    "        self.conv_1 = nn.Conv2d(new_bands, groups*groups_width, (1, 1), groups=groups)\n",
    "        self.bn_1 = nn.BatchNorm2d(groups*groups_width)\n",
    "        self.res0 = Res(groups*groups_width, (3, 3), (1, 1), groups_s=groups)\n",
    "\n",
    "        # Dual Residual Block (Ref-RDACN)\n",
    "        self.bn1 = nn.BatchNorm2d(emb_dim)\n",
    "        self.conv1 = nn.Conv2d(emb_dim, 64, kernel_size=1, padding=0)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, padding=1, groups=64)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, emb_dim, kernel_size=1, padding=0)\n",
    "\n",
    "        # Vision Transformer\n",
    "        self.patch_embeddings = PatchEmbeddings(patch_size=patch_size, patch_dim=patch_dim, emb_dim=emb_dim)\n",
    "        self.pos_embeddings = PositionalEmbeddings(num_pos=self.num_patches, dim=emb_dim)\n",
    "        self.transformer = transformer(dim=emb_dim, num_layers=num_layers, num_heads=num_heads, \n",
    "                                       head_dim=head_dim, hidden_dim=hidden_dim, num_patch=self.num_patch, patch_size=patch_size)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        self.pool = Pooling(pool=pool)\n",
    "        self.classifier = Classifier(dim=emb_dim, num_classes=num_classes)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.pad(x).squeeze(1)\n",
    "        b, c, h, w = x.shape\n",
    "        x = F.relu(self.bn_1(self.conv_1(x)))\n",
    "        x = self.res0(x)\n",
    "\n",
    "        x4 = self.patch_embeddings(x)\n",
    "        x5 = self.pos_embeddings(x4)\n",
    "        x6 = self.transformer(x5)\n",
    "\n",
    "        x4_c = x4.reshape(b, -1, h, w)\n",
    "        x_c1 = self.conv1(self.act(self.bn1(x4_c)))\n",
    "        x_c2 = self.conv2(self.act(self.bn2(x_c1)))\n",
    "        x_c3 = self.conv3(self.act(self.bn3(x_c2)))\n",
    "\n",
    "        x7 = self.pool(self.dropout(x6 + x_c3.reshape(b, h*w, -1)))\n",
    "\n",
    "        return self.classifier(x7)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    input = torch.randn(size=(751, 1, 25, 12, 12))\n",
    "    print(\"input shape:\", input.shape)\n",
    "    model = CTMixer(channels=25, num_classes=15, image_size=12, datasetname='Houston', num_layers=1, num_heads=4)\n",
    "\n",
    "    # Get the model summary\n",
    "    summary(model, input_size=(751, 1, 25, 12, 12), device=\"cpu\")\n",
    "\n",
    "    # Calculate the FLOPs\n",
    "    macs, params = get_model_complexity_info(model, (1, 25, 12, 12), as_strings=True, print_per_layer_stat=True)\n",
    "    print(f\"MACs: {macs}\")\n",
    "    print(f\"Parameters: {params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "486efe80-d8a7-4f03-9a4e-657ed4bd9e69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, cohen_kappa_score\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Convert the data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(Xtrain, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(ytrain, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(Xtest, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(ytest, dtype=torch.long)\n",
    "\n",
    "# Create custom datasets\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc3d3da8-c0e1-41e6-bb33-08c6aa7e636f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CTMixer(\n",
       "  (act): ReLU(inplace=True)\n",
       "  (pad): ReplicationPad3d((0, 0, 0, 0, 0, 0))\n",
       "  (conv_1): Conv2d(25, 320, kernel_size=(1, 1), stride=(1, 1), groups=5)\n",
       "  (bn_1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (res0): Res(\n",
       "    (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=5)\n",
       "    (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=5)\n",
       "    (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (res2): Res2(\n",
       "      (conv1): Conv2d(320, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
       "  (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (patch_embeddings): PatchEmbeddings(\n",
       "    (patchify): Rearrange('b c (h p1) (w p2) -> b (h w) c p1 p2', p1=1, p2=1)\n",
       "    (flatten): Flatten(start_dim=2, end_dim=-1)\n",
       "    (proj): Linear(in_features=320, out_features=128, bias=True)\n",
       "  )\n",
       "  (pos_embeddings): PositionalEmbeddings()\n",
       "  (transformer): transformer(\n",
       "    (layers): ModuleList(\n",
       "      (0): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): Attention_Conv(\n",
       "            (attn): Softmax(dim=-1)\n",
       "            (act): ReLU(inplace=True)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (qkv): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), groups=128, bias=False)\n",
       "            (avgpool): AdaptiveAvgPool1d(output_size=128)\n",
       "            (qs): Conv2d(128, 128, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), groups=128, bias=False)\n",
       "            (ks): Conv2d(128, 128, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), groups=128, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): FeedForward_Conv(\n",
       "            (conv1): Sequential(\n",
       "              (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            )\n",
       "            (conv2): Sequential(\n",
       "              (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "            )\n",
       "            (conv3): Sequential(\n",
       "              (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (pool): Pooling()\n",
       "  (classifier): Classifier(\n",
       "    (model): Sequential(\n",
       "      (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (1): Linear(in_features=128, out_features=15, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize model, loss function, and optimizer\n",
    "model = CTMixer(channels=25, num_classes=15, image_size=12, datasetname='Houston', num_layers=1, num_heads=4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4979640-2779-40b9-b54e-4f94a0bcfb22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 2.0663\n",
      "Epoch [2/50], Loss: 1.0210\n",
      "Epoch [3/50], Loss: 0.6980\n",
      "Epoch [4/50], Loss: 0.5355\n",
      "Epoch [5/50], Loss: 0.4386\n",
      "Epoch [6/50], Loss: 0.3419\n",
      "Epoch [7/50], Loss: 0.2751\n",
      "Epoch [8/50], Loss: 0.1718\n",
      "Epoch [9/50], Loss: 0.1641\n",
      "Epoch [10/50], Loss: 0.2194\n",
      "Epoch [11/50], Loss: 0.2232\n",
      "Epoch [12/50], Loss: 0.0958\n",
      "Epoch [13/50], Loss: 0.0639\n",
      "Epoch [14/50], Loss: 0.0627\n",
      "Epoch [15/50], Loss: 0.0395\n",
      "Epoch [16/50], Loss: 0.0563\n",
      "Epoch [17/50], Loss: 0.0358\n",
      "Epoch [18/50], Loss: 0.0226\n",
      "Epoch [19/50], Loss: 0.0142\n",
      "Epoch [20/50], Loss: 0.0295\n",
      "Epoch [21/50], Loss: 0.0565\n",
      "Epoch [22/50], Loss: 0.0317\n",
      "Epoch [23/50], Loss: 0.0321\n",
      "Epoch [24/50], Loss: 0.0123\n",
      "Epoch [25/50], Loss: 0.0089\n",
      "Epoch [26/50], Loss: 0.0166\n",
      "Epoch [27/50], Loss: 0.0120\n",
      "Epoch [28/50], Loss: 0.0164\n",
      "Epoch [29/50], Loss: 0.0242\n",
      "Epoch [30/50], Loss: 0.0394\n",
      "Epoch [31/50], Loss: 0.0629\n",
      "Epoch [32/50], Loss: 0.0526\n",
      "Epoch [33/50], Loss: 0.1603\n",
      "Epoch [34/50], Loss: 0.1092\n",
      "Epoch [35/50], Loss: 0.0744\n",
      "Epoch [36/50], Loss: 0.0169\n",
      "Epoch [37/50], Loss: 0.0453\n",
      "Epoch [38/50], Loss: 0.0328\n",
      "Epoch [39/50], Loss: 0.0133\n",
      "Epoch [40/50], Loss: 0.0099\n",
      "Epoch [41/50], Loss: 0.0313\n",
      "Epoch [42/50], Loss: 0.0474\n",
      "Epoch [43/50], Loss: 0.1443\n",
      "Epoch [44/50], Loss: 0.1022\n",
      "Epoch [45/50], Loss: 0.0427\n",
      "Epoch [46/50], Loss: 0.0100\n",
      "Epoch [47/50], Loss: 0.0110\n",
      "Epoch [48/50], Loss: 0.0096\n",
      "Epoch [49/50], Loss: 0.0056\n",
      "Epoch [50/50], Loss: 0.0072\n",
      "Training time: 127.56 seconds\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 50\n",
    "start_time = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}')\n",
    "end_time = time.time()\n",
    "print(f'Training time: {end_time - start_time:.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a97697c-c4b7-4361-8733-472238f69ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test set: 92.09%\n",
      "Test time: 13.21 seconds\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    start_time = time.time()\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "    end_time = time.time()  # End timing\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "print(f'Accuracy of the model on the test set: {100 * accuracy:.2f}%')\n",
    "print(f'Test time: {end_time - start_time:.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3471bea-6e5c-4528-8c56-960f93e50e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.89      0.99      0.94      1188\n",
      "     Class 1       0.98      0.93      0.95      1191\n",
      "     Class 2       1.00      1.00      1.00       662\n",
      "     Class 3       0.93      0.98      0.96      1182\n",
      "     Class 4       0.93      1.00      0.96      1180\n",
      "     Class 5       0.99      0.94      0.96       309\n",
      "     Class 6       0.96      0.79      0.86      1205\n",
      "     Class 7       0.93      0.93      0.93      1182\n",
      "     Class 8       0.78      0.90      0.84      1189\n",
      "     Class 9       0.98      0.77      0.86      1166\n",
      "    Class 10       0.88      0.98      0.92      1173\n",
      "    Class 11       0.87      0.92      0.89      1171\n",
      "    Class 12       0.96      0.67      0.79       446\n",
      "    Class 13       0.99      1.00      0.99       407\n",
      "    Class 14       1.00      1.00      1.00       627\n",
      "\n",
      "    accuracy                           0.92     14278\n",
      "   macro avg       0.94      0.92      0.92     14278\n",
      "weighted avg       0.93      0.92      0.92     14278\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1176    1    0   11    0    0    0    0    0    0    0    0    0    0\n",
      "     0]\n",
      " [  78 1103    0    3    0    0    0    0    6    0    1    0    0    0\n",
      "     0]\n",
      " [   0    0  662    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0]\n",
      " [   9    1    0 1162    9    0    0    0    0    0    0    1    0    0\n",
      "     0]\n",
      " [   0    0    0    0 1180    0    0    0    0    0    0    0    0    0\n",
      "     0]\n",
      " [   3    0    0    0    0  289    7    0    4    0    0    0    6    0\n",
      "     0]\n",
      " [  38   11    0   41   15    1  948   11  101    0   32    6    1    0\n",
      "     0]\n",
      " [   1    0    0    1   24    0   21 1100   23    3    4    2    0    0\n",
      "     3]\n",
      " [   4    0    0    2   28    0    0    1 1073    8   44   29    0    0\n",
      "     0]\n",
      " [   5    5    0   12    8    0    1   40   64  899   31   98    3    0\n",
      "     0]\n",
      " [   1    0    0    3    8    3    0    1    1    2 1146    1    1    6\n",
      "     0]\n",
      " [   0    0    0    6    1    0    4    1   39    0   44 1076    0    0\n",
      "     0]\n",
      " [   0    1    0    2    1    0    6   35   59    5    7   30  300    0\n",
      "     0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0  407\n",
      "     0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "   627]]\n",
      "Kappa Accuracy: 0.9144\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "class_report = classification_report(all_labels, all_preds, target_names=[f'Class {i}' for i in range(15)])\n",
    "print('Classification Report:')\n",
    "print(class_report)\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "\n",
    "# Kappa accuracy\n",
    "kappa = cohen_kappa_score(all_labels, all_preds)\n",
    "print(f'Kappa Accuracy: {kappa:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de7e8bfc-282b-4123-9a3e-9e0b8d07d5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy (OA): 0.9209\n",
      "Average Accuracy (AA): 0.9196\n",
      "Kappa Coefficient: 0.9144\n",
      "Class 1 Accuracy: 0.9899\n",
      "Class 2 Accuracy: 0.9261\n",
      "Class 3 Accuracy: 1.0000\n",
      "Class 4 Accuracy: 0.9831\n",
      "Class 5 Accuracy: 1.0000\n",
      "Class 6 Accuracy: 0.9353\n",
      "Class 7 Accuracy: 0.7867\n",
      "Class 8 Accuracy: 0.9306\n",
      "Class 9 Accuracy: 0.9024\n",
      "Class 10 Accuracy: 0.7710\n",
      "Class 11 Accuracy: 0.9770\n",
      "Class 12 Accuracy: 0.9189\n",
      "Class 13 Accuracy: 0.6726\n",
      "Class 14 Accuracy: 1.0000\n",
      "Class 15 Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Overall Accuracy\n",
    "oa = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "# Calculate per-class accuracy from the confusion matrix\n",
    "class_accuracy = cm.diagonal() / cm.sum(axis=1)\n",
    "# Average Accuracy\n",
    "aa = np.mean(class_accuracy)\n",
    "\n",
    "# Kappa Coefficient\n",
    "kappa = cohen_kappa_score(all_labels, all_preds)\n",
    "\n",
    "print(f'Overall Accuracy (OA): {oa:.4f}')\n",
    "print(f'Average Accuracy (AA): {aa:.4f}')\n",
    "print(f'Kappa Coefficient: {kappa:.4f}')\n",
    "for i, acc in enumerate(class_accuracy): print(f'Class {i+1} Accuracy: {acc:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
