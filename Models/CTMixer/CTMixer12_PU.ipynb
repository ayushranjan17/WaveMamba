{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f4eea1e0-1387-4deb-9ade-491a28e1267e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchinfo in /home/cvlab/anaconda3/lib/python3.11/site-packages (1.8.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "615fb01b-d7f5-478f-bb9f-0d411056796d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-12 12:47:54.411383: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-12 12:47:54.439467: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-12 12:47:54.439509: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-12 12:47:54.460614: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-12 12:47:55.481848: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spectral in /home/cvlab/anaconda3/lib/python3.11/site-packages (0.23.1)\n",
      "Requirement already satisfied: numpy in /home/cvlab/anaconda3/lib/python3.11/site-packages (from spectral) (1.23.5)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Conv2D, Conv3D, Flatten, Dense, Reshape, BatchNormalization\n",
    "from keras.layers import Dropout, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras import backend as Kb\n",
    "from keras.layers import Lambda\n",
    "from keras.layers import Activation\n",
    "from keras.layers import add, concatenate\n",
    "from keras.layers import AveragePooling2D\n",
    "from keras.utils import plot_model\n",
    " \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, cohen_kappa_score\n",
    " \n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "from sklearn.decomposition import PCA\n",
    "from operator import truediv\n",
    "\n",
    "\n",
    "from plotly.offline import init_notebook_mode\n",
    " \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import os\n",
    "!pip install spectral\n",
    "import spectral\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2daee46f-b8ad-4d65-873c-b1271d74b849",
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyFA(X, numComponents=75):\n",
    "    newX = np.reshape(X, (-1, X.shape[2]))\n",
    "    fa = FactorAnalysis(n_components=numComponents, random_state=0)\n",
    "    newX = fa.fit_transform(newX)\n",
    "    newX = np.reshape(newX, (X.shape[0],X.shape[1], numComponents))\n",
    "    return newX, fa\n",
    "## GLOBAL VARIABLES\n",
    "dataset = 'PU'\n",
    "test_ratio = 0.95\n",
    "windowSize = 12\n",
    "def loadData(name):\n",
    "    data_path = os.path.join(os.getcwd(),'data')\n",
    "    if name == 'IP':\n",
    "        data = sio.loadmat(os.path.join(data_path, 'Indian_pines_corrected.mat'))['indian_pines_corrected']\n",
    "        labels = sio.loadmat(os.path.join(data_path, 'Indian_pines_gt.mat'))['indian_pines_gt']\n",
    "    elif name == 'SA':\n",
    "        data = sio.loadmat(os.path.join(data_path, 'Salinas_corrected.mat'))['salinas_corrected']\n",
    "        labels = sio.loadmat(os.path.join(data_path, 'Salinas_gt.mat'))['salinas_gt']\n",
    "    elif name == 'PU':\n",
    "        data = sio.loadmat(os.path.join(data_path, 'PaviaU.mat'))['paviaU']\n",
    "        labels = sio.loadmat(os.path.join(data_path, 'PaviaU_gt.mat'))['paviaU_gt']\n",
    "    \n",
    "    return data, labels\n",
    "def splitTrainTestSet(X, y, testRatio, randomState=345):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testRatio, random_state=randomState,\n",
    "                                                        stratify=y)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "def padWithZeros(X, margin=2):\n",
    "    newX = np.zeros((X.shape[0] + 2 * margin, X.shape[1] + 2* margin, X.shape[2]))\n",
    "    x_offset = margin\n",
    "    y_offset = margin\n",
    "    newX[x_offset:X.shape[0] + x_offset, y_offset:X.shape[1] + y_offset, :] = X\n",
    "    return newX\n",
    "def createImageCubes(X, y, windowSize=8, removeZeroLabels = True):\n",
    "    margin = int((windowSize) / 2)\n",
    "    zeroPaddedX = padWithZeros(X, margin=margin)\n",
    "    # split patches\n",
    "    patchesData = np.zeros((X.shape[0] * X.shape[1], windowSize, windowSize, X.shape[2]))\n",
    "    patchesLabels = np.zeros((X.shape[0] * X.shape[1]))\n",
    "    patchIndex = 0\n",
    "    for r in range(margin, zeroPaddedX.shape[0] - margin):\n",
    "        for c in range(margin, zeroPaddedX.shape[1] - margin):\n",
    "            patch = zeroPaddedX[r - margin:r + margin , c - margin:c + margin ]   \n",
    "            patchesData[patchIndex, :, :, :] = patch\n",
    "            patchesLabels[patchIndex] = y[r-margin, c-margin]\n",
    "            patchIndex = patchIndex + 1\n",
    "    if removeZeroLabels:\n",
    "        patchesData = patchesData[patchesLabels>0,:,:,:]\n",
    "        patchesLabels = patchesLabels[patchesLabels>0]\n",
    "        patchesLabels -= 1\n",
    "    return patchesData, patchesLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9376abba-2653-4854-9760-451ba3b14875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((610, 340, 103), (610, 340))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = loadData(dataset)\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14b6f9a8-2046-4c3d-acf2-b296d103ab98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((42776, 12, 12, 103), (42776,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = createImageCubes(X, y, windowSize=windowSize)\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1628d0e-4da5-41e9-99c6-85c3c91fd9da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2138, 12, 12, 103), (40638, 12, 12, 103), (2138,), (40638,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = splitTrainTestSet(X, y, test_ratio)\n",
    "\n",
    "Xtrain.shape, Xtest.shape, ytrain.shape, ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7be6228-b14b-4af0-9a5a-b42afa50f804",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = Xtrain.transpose(0, 3, 1, 2).reshape(2138, 1, 103, 12, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3f4a4ee-f1a8-4e03-a769-6b78a5f5d06e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2138, 1, 103, 12, 12)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2b96bc8-9e85-49f8-b6ab-d1407c65ea40",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest = Xtest.transpose(0, 3, 1, 2).reshape(40638, 1, 103, 12, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20e0c85e-9e77-4522-9a5b-76b391c79321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40638, 1, 103, 12, 12)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42580f39-ef7c-41d3-8b06-d701efaea90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape: torch.Size([2138, 1, 103, 12, 12])\n",
      "320\n",
      "output shape: torch.Size([2138, 9])\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchinfo import summary\n",
    "from transformer import transformer\n",
    "from embeddings import (PatchEmbeddings, CLSToken, PositionalEmbeddings)\n",
    "\n",
    "class Pooling(nn.Module):\n",
    "    def __init__(self, pool: str = \"mean\"):\n",
    "        super().__init__()\n",
    "        if pool not in [\"mean\", \"cls\"]:\n",
    "            raise ValueError(\"pool must be one of {mean, cls}\")\n",
    "\n",
    "        self.pool_fn = self.mean_pool if pool == \"mean\" else self.cls_pool\n",
    "\n",
    "    def mean_pool(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return x.mean(dim=1)\n",
    "\n",
    "    def cls_pool(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return x[:, 0]\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.pool_fn(x)\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, dim: int, num_classes: int):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.LayerNorm(dim),\n",
    "            nn.Linear(in_features=dim, out_features=num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.model(x)\n",
    "\n",
    "class Res2(nn.Module):\n",
    "    def __init__(self, in_channels, inter_channels, kernel_size, padding=0):\n",
    "        super(Res2, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, inter_channels, kernel_size=kernel_size, padding=padding)\n",
    "        self.bn1 = nn.BatchNorm2d(inter_channels)\n",
    "        self.conv2 = nn.Conv2d(inter_channels, in_channels, kernel_size=kernel_size, padding=padding)\n",
    "        self.bn2 = nn.BatchNorm2d(in_channels)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.bn1(self.conv1(X)))\n",
    "        X = self.bn2(self.conv2(X))\n",
    "        return X\n",
    "\n",
    "class Res(nn.Module):\n",
    "    def __init__(self, in_channels, kernel_size, padding, groups_s):\n",
    "        super(Res, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, in_channels, kernel_size=kernel_size, padding=padding, groups=groups_s)\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "        self.conv2 = nn.Conv2d(in_channels, in_channels, kernel_size=kernel_size, padding=padding, groups=groups_s)\n",
    "        self.bn2 = nn.BatchNorm2d(in_channels)\n",
    "        self.res2 = Res2(in_channels, 32, kernel_size=kernel_size, padding=padding)\n",
    "\n",
    "    def forward(self, X):\n",
    "        Y = F.relu(self.bn1(self.conv1(X)))\n",
    "        Y = self.bn2(self.conv2(Y))\n",
    "        Z = self.res2(X)\n",
    "        return F.relu(X + Y + Z)\n",
    "\n",
    "class CTMixer(nn.Module):\n",
    "    def __init__(self, channels, num_classes, image_size, datasetname, num_layers: int=1, num_heads: int=4, \n",
    "                 patch_size: int = 1, emb_dim: int = 128, head_dim = 64, hidden_dim: int = 64, pool: str = \"mean\"):\n",
    "        super().__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.channels = channels\n",
    "        self.image_size = image_size\n",
    "        self.num_patches = (image_size // patch_size) ** 2\n",
    "        self.num_patch = int(math.sqrt(self.num_patches))\n",
    "        self.act = nn.ReLU(inplace=True)\n",
    "        patch_dim = channels * patch_size ** 2\n",
    "\n",
    "        # Conv Preprocessing Module (Ref-SPRN)\n",
    "        if datasetname == 'IndianPines':\n",
    "            groups = 10  # Adjusted groups to match channels\n",
    "            groups_width = 40  # Adjusted width to match groups\n",
    "        elif datasetname == 'PaviaU':\n",
    "            groups = 5\n",
    "            groups_width = 64\n",
    "        elif datasetname == 'Salinas':\n",
    "            groups = 11\n",
    "            groups_width = 37\n",
    "        elif datasetname == 'Houston':\n",
    "            groups = 5\n",
    "            groups_width = 64\n",
    "        else:\n",
    "            groups = 11\n",
    "            groups_width = 37\n",
    "\n",
    "        new_bands = math.ceil(channels/groups) * groups\n",
    "        patch_dim = (groups*groups_width) * patch_size ** 2\n",
    "        pad_size = new_bands - channels\n",
    "        self.pad = nn.ReplicationPad3d((0, 0, 0, 0, 0, pad_size))\n",
    "        self.conv_1 = nn.Conv2d(new_bands, groups*groups_width, (1, 1), groups=groups)\n",
    "        self.bn_1 = nn.BatchNorm2d(groups*groups_width)\n",
    "        self.res0 = Res(groups*groups_width, (3, 3), (1, 1), groups_s=groups)\n",
    "\n",
    "        # Dual Residual Block (Ref-RDACN)\n",
    "        self.bn1 = nn.BatchNorm2d(emb_dim)\n",
    "        self.conv1 = nn.Conv2d(emb_dim, 64, kernel_size=1, padding=0)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, padding=1, groups=64)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, emb_dim, kernel_size=1, padding=0)\n",
    "\n",
    "        # Vision Transformer\n",
    "        self.patch_embeddings = PatchEmbeddings(patch_size=patch_size, patch_dim=patch_dim, emb_dim=emb_dim)\n",
    "        self.pos_embeddings = PositionalEmbeddings(num_pos=self.num_patches, dim=emb_dim)\n",
    "        self.transformer = transformer(dim=emb_dim, num_layers=num_layers, num_heads=num_heads, \n",
    "                                       head_dim=head_dim, hidden_dim=hidden_dim, num_patch=self.num_patch, patch_size=patch_size)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        self.pool = Pooling(pool=pool)\n",
    "        self.classifier = Classifier(dim=emb_dim, num_classes=num_classes)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.pad(x).squeeze(1)\n",
    "        b, c, h, w = x.shape\n",
    "        x = F.relu(self.bn_1(self.conv_1(x)))\n",
    "        x = self.res0(x)\n",
    "\n",
    "        x4 = self.patch_embeddings(x)\n",
    "        x5 = self.pos_embeddings(x4)\n",
    "        x6 = self.transformer(x5)\n",
    "\n",
    "        x4_c = x4.reshape(b, -1, h, w)\n",
    "        x_c1 = self.conv1(self.act(self.bn1(x4_c)))\n",
    "        x_c2 = self.conv2(self.act(self.bn2(x_c1)))\n",
    "        x_c3 = self.conv3(self.act(self.bn3(x_c2)))\n",
    "\n",
    "        x7 = self.pool(self.dropout(x6 + x_c3.reshape(b, h*w, -1)))\n",
    "\n",
    "        return self.classifier(x7)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    input = torch.randn(size=(2138, 1, 103, 12, 12))\n",
    "    print(\"input shape:\", input.shape)\n",
    "    model = CTMixer(channels=103, num_classes=9, image_size=12, datasetname='PaviaU', num_layers=1, num_heads=4)\n",
    "    summary(model, input_size=(2138, 1, 103, 12, 12), device=\"cpu\")\n",
    "    print(\"output shape:\", model(input).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "486efe80-d8a7-4f03-9a4e-657ed4bd9e69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, cohen_kappa_score\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Convert the data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(Xtrain, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(ytrain, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(Xtest, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(ytest, dtype=torch.long)\n",
    "\n",
    "# Create custom datasets\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc3d3da8-c0e1-41e6-bb33-08c6aa7e636f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CTMixer(\n",
       "  (act): ReLU(inplace=True)\n",
       "  (pad): ReplicationPad3d((0, 0, 0, 0, 0, 2))\n",
       "  (conv_1): Conv2d(105, 320, kernel_size=(1, 1), stride=(1, 1), groups=5)\n",
       "  (bn_1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (res0): Res(\n",
       "    (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=5)\n",
       "    (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=5)\n",
       "    (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (res2): Res2(\n",
       "      (conv1): Conv2d(320, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
       "  (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (patch_embeddings): PatchEmbeddings(\n",
       "    (patchify): Rearrange('b c (h p1) (w p2) -> b (h w) c p1 p2', p1=1, p2=1)\n",
       "    (flatten): Flatten(start_dim=2, end_dim=-1)\n",
       "    (proj): Linear(in_features=320, out_features=128, bias=True)\n",
       "  )\n",
       "  (pos_embeddings): PositionalEmbeddings()\n",
       "  (transformer): transformer(\n",
       "    (layers): ModuleList(\n",
       "      (0): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): Attention_Conv(\n",
       "            (attn): Softmax(dim=-1)\n",
       "            (act): ReLU(inplace=True)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (qkv): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), groups=128, bias=False)\n",
       "            (avgpool): AdaptiveAvgPool1d(output_size=128)\n",
       "            (qs): Conv2d(128, 128, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), groups=128, bias=False)\n",
       "            (ks): Conv2d(128, 128, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), groups=128, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): FeedForward_Conv(\n",
       "            (conv1): Sequential(\n",
       "              (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            )\n",
       "            (conv2): Sequential(\n",
       "              (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "            )\n",
       "            (conv3): Sequential(\n",
       "              (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (pool): Pooling()\n",
       "  (classifier): Classifier(\n",
       "    (model): Sequential(\n",
       "      (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (1): Linear(in_features=128, out_features=9, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize model, loss function, and optimizer\n",
    "model = CTMixer(channels=103, num_classes=9, image_size=12, datasetname='PaviaU', num_layers=1, num_heads=4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb7b22c-83ee-4a77-911d-addfe5ed49b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4979640-2779-40b9-b54e-4f94a0bcfb22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 0.8930\n",
      "Epoch [2/50], Loss: 0.5241\n",
      "Epoch [3/50], Loss: 0.4205\n",
      "Epoch [4/50], Loss: 0.2697\n",
      "Epoch [5/50], Loss: 0.2413\n",
      "Epoch [6/50], Loss: 0.1314\n",
      "Epoch [7/50], Loss: 0.1520\n",
      "Epoch [8/50], Loss: 0.1167\n",
      "Epoch [9/50], Loss: 0.0819\n",
      "Epoch [10/50], Loss: 0.0945\n",
      "Epoch [11/50], Loss: 0.1127\n",
      "Epoch [12/50], Loss: 0.0731\n",
      "Epoch [13/50], Loss: 0.0766\n",
      "Epoch [14/50], Loss: 0.0982\n",
      "Epoch [15/50], Loss: 0.0404\n",
      "Epoch [16/50], Loss: 0.0860\n",
      "Epoch [17/50], Loss: 0.0554\n",
      "Epoch [18/50], Loss: 0.0160\n",
      "Epoch [19/50], Loss: 0.0228\n",
      "Epoch [20/50], Loss: 0.0320\n",
      "Epoch [21/50], Loss: 0.0515\n",
      "Epoch [22/50], Loss: 0.0472\n",
      "Epoch [23/50], Loss: 0.0574\n",
      "Epoch [24/50], Loss: 0.0660\n",
      "Epoch [25/50], Loss: 0.0324\n",
      "Epoch [26/50], Loss: 0.0172\n",
      "Epoch [27/50], Loss: 0.0205\n",
      "Epoch [28/50], Loss: 0.0308\n",
      "Epoch [29/50], Loss: 0.0244\n",
      "Epoch [30/50], Loss: 0.0741\n",
      "Epoch [31/50], Loss: 0.0350\n",
      "Epoch [32/50], Loss: 0.0376\n",
      "Epoch [33/50], Loss: 0.0371\n",
      "Epoch [34/50], Loss: 0.0164\n",
      "Epoch [35/50], Loss: 0.0273\n",
      "Epoch [36/50], Loss: 0.0298\n",
      "Epoch [37/50], Loss: 0.0210\n",
      "Epoch [38/50], Loss: 0.0384\n",
      "Epoch [39/50], Loss: 0.0268\n",
      "Epoch [40/50], Loss: 0.0125\n",
      "Epoch [41/50], Loss: 0.0546\n",
      "Epoch [42/50], Loss: 0.0395\n",
      "Epoch [43/50], Loss: 0.0372\n",
      "Epoch [44/50], Loss: 0.0231\n",
      "Epoch [45/50], Loss: 0.0205\n",
      "Epoch [46/50], Loss: 0.0228\n",
      "Epoch [47/50], Loss: 0.0253\n",
      "Epoch [48/50], Loss: 0.0235\n",
      "Epoch [49/50], Loss: 0.0105\n",
      "Epoch [50/50], Loss: 0.0098\n",
      "Training time: 423.31 seconds\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 50\n",
    "start_time = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}')\n",
    "end_time = time.time()\n",
    "print(f'Training time: {end_time - start_time:.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a97697c-c4b7-4361-8733-472238f69ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test set: 73.46%\n",
      "Test time: 41.11 seconds\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    start_time = time.time()\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "    end_time = time.time()  # End timing\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "print(f'Accuracy of the model on the test set: {100 * accuracy:.2f}%')\n",
    "print(f'Test time: {end_time - start_time:.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3471bea-6e5c-4528-8c56-960f93e50e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.98      0.84      0.90      6299\n",
      "     Class 1       0.65      1.00      0.79     17717\n",
      "     Class 2       0.92      0.37      0.53      1994\n",
      "     Class 3       0.72      0.98      0.83      2911\n",
      "     Class 4       0.91      0.80      0.85      1278\n",
      "     Class 5       1.00      0.01      0.02      4778\n",
      "     Class 6       1.00      0.70      0.82      1263\n",
      "     Class 7       0.99      0.13      0.22      3498\n",
      "     Class 8       0.98      0.97      0.98       900\n",
      "\n",
      "    accuracy                           0.73     40638\n",
      "   macro avg       0.91      0.64      0.66     40638\n",
      "weighted avg       0.82      0.73      0.67     40638\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 5274   846    28   141     1     0     1     0     8]\n",
      " [    0 17713     0     4     0     0     0     0     0]\n",
      " [   42  1178   747    21     1     0     0     5     0]\n",
      " [    1    51     8  2850     0     0     0     0     1]\n",
      " [    0   255     0     4  1019     0     0     0     0]\n",
      " [    0  4715     0     9     0    54     0     0     0]\n",
      " [   72   204     1    10    89     0   885     0     2]\n",
      " [    5  2123    24   897     6     0     0   439     4]\n",
      " [    0    10     0    18     0     0     0     0   872]]\n",
      "Kappa Accuracy: 0.6084\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "class_report = classification_report(all_labels, all_preds, target_names=[f'Class {i}' for i in range(9)])\n",
    "print('Classification Report:')\n",
    "print(class_report)\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "\n",
    "# Kappa accuracy\n",
    "kappa = cohen_kappa_score(all_labels, all_preds)\n",
    "print(f'Kappa Accuracy: {kappa:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de7e8bfc-282b-4123-9a3e-9e0b8d07d5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy (OA): 0.7346\n",
      "Average Accuracy (AA): 0.6438\n",
      "Kappa Coefficient: 0.6084\n",
      "Class 1 Accuracy: 0.8373\n",
      "Class 2 Accuracy: 0.9998\n",
      "Class 3 Accuracy: 0.3746\n",
      "Class 4 Accuracy: 0.9790\n",
      "Class 5 Accuracy: 0.7973\n",
      "Class 6 Accuracy: 0.0113\n",
      "Class 7 Accuracy: 0.7007\n",
      "Class 8 Accuracy: 0.1255\n",
      "Class 9 Accuracy: 0.9689\n"
     ]
    }
   ],
   "source": [
    "# Overall Accuracy\n",
    "oa = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "# Calculate per-class accuracy from the confusion matrix\n",
    "class_accuracy = cm.diagonal() / cm.sum(axis=1)\n",
    "# Average Accuracy\n",
    "aa = np.mean(class_accuracy)\n",
    "\n",
    "# Kappa Coefficient\n",
    "kappa = cohen_kappa_score(all_labels, all_preds)\n",
    "\n",
    "print(f'Overall Accuracy (OA): {oa:.4f}')\n",
    "print(f'Average Accuracy (AA): {aa:.4f}')\n",
    "print(f'Kappa Coefficient: {kappa:.4f}')\n",
    "for i, acc in enumerate(class_accuracy): print(f'Class {i+1} Accuracy: {acc:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
