{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "761339fd-d5b4-4e90-9a9c-9a877f91334b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "from torchsummaryX import summary\n",
    "\n",
    "from utils.dataset import load_mat_hsi, sample_gt, HSIDataset\n",
    "from utils.utils import split_info_print, metrics, show_results\n",
    "from utils.scheduler import load_scheduler\n",
    "from models.get_model import get_model\n",
    "from train import train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30148a97-d020-4636-aa1f-8c9992992e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "from fvcore.nn import FlopCountAnalysis, parameter_count\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d0c0d95-ed7a-490b-b122-9d8f70ba716b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiments will run on GPU device 0\n",
      "model = cnn3d\n",
      "dataset = pu\n",
      "dataset folder = ./datasets\n",
      "patch size = 12\n",
      "batch size = 32\n",
      "total epoch = 50\n",
      "0.015 for training, 0.015 for validation and 0.97 for testing\n",
      "running an experiment with the cnn3d model\n",
      "run 1 / 1\n",
      "(610, 340)\n",
      "CNN3D(\n",
      "  (conv1): Conv3d(1, 20, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "  (pool1): Conv3d(20, 20, kernel_size=(3, 1, 1), stride=(2, 1, 1), padding=(1, 0, 0))\n",
      "  (conv2): Conv3d(20, 35, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 0, 0))\n",
      "  (pool2): Conv3d(35, 35, kernel_size=(3, 1, 1), stride=(2, 1, 1), padding=(1, 0, 0))\n",
      "  (conv3): Conv3d(35, 35, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
      "  (conv4): Conv3d(35, 35, kernel_size=(2, 1, 1), stride=(2, 1, 1), padding=(1, 0, 0))\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc): Linear(in_features=31360, out_features=9, bias=True)\n",
      ")\n",
      "class train val test\n",
      "Asphalt 99 100 6432\n",
      "Meadows 279 280 18090\n",
      "Gravel 32 31 2036\n",
      "Trees 46 46 2972\n",
      "Painted metal sheets 20 20 1305\n",
      "Bare Soil 75 76 4878\n",
      "Bitumen 20 20 1290\n",
      "Self-Blocking Bricks 56 55 3571\n",
      "Shadows 14 14 919\n",
      "network information:\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv3d-1      [-1, 20, 101, 10, 10]             560\n",
      "            Conv3d-2       [-1, 20, 51, 10, 10]           1,220\n",
      "            Conv3d-3         [-1, 35, 51, 8, 8]          18,935\n",
      "            Conv3d-4         [-1, 35, 26, 8, 8]           3,710\n",
      "            Conv3d-5         [-1, 35, 26, 8, 8]           3,710\n",
      "            Conv3d-6         [-1, 35, 14, 8, 8]           2,485\n",
      "           Dropout-7                [-1, 31360]               0\n",
      "            Linear-8                    [-1, 9]         282,249\n",
      "================================================================\n",
      "Total params: 312,869\n",
      "Trainable params: 312,869\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.06\n",
      "Forward/backward pass size (MB): 4.56\n",
      "Params size (MB): 1.19\n",
      "Estimated Total Size (MB): 5.81\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training the network:   0%|                              | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train at epoch 1/50, loss=1.785324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training the network:   2%|▍                     | 1/50 [00:01<00:57,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1: best validation OA = 0.4626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training the network:   4%|▉                     | 2/50 [00:02<00:50,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 2: best validation OA = 0.6822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training the network:   6%|█▎                    | 3/50 [00:03<00:47,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 3: best validation OA = 0.7274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training the network:   8%|█▊                    | 4/50 [00:04<00:45,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 4: best validation OA = 0.7617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training the network:  12%|██▋                   | 6/50 [00:06<00:43,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 6: best validation OA = 0.7850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training the network:  14%|███                   | 7/50 [00:06<00:41,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 7: best validation OA = 0.8224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training the network:  16%|███▌                  | 8/50 [00:07<00:40,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 8: best validation OA = 0.8427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training the network:  18%|███▉                  | 9/50 [00:09<00:39,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train at epoch 10/50, loss=0.458903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training the network:  20%|████▏                | 10/50 [00:09<00:38,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 10: best validation OA = 0.8723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training the network:  24%|█████                | 12/50 [00:11<00:36,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 12: best validation OA = 0.8723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training the network:  30%|██████▎              | 15/50 [00:14<00:33,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 15: best validation OA = 0.8754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training the network:  38%|███████▉             | 19/50 [00:18<00:30,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 19: best validation OA = 0.9097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training the network:  38%|███████▉             | 19/50 [00:19<00:30,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train at epoch 20/50, loss=0.325553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training the network:  48%|██████████           | 24/50 [00:24<00:28,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 24: best validation OA = 0.9206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training the network:  58%|████████████▏        | 29/50 [00:30<00:23,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train at epoch 30/50, loss=0.210695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training the network:  60%|████████████▌        | 30/50 [00:31<00:22,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 30: best validation OA = 0.9377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training the network:  78%|████████████████▍    | 39/50 [00:42<00:12,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train at epoch 40/50, loss=0.251197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training the network:  98%|████████████████████▌| 49/50 [00:54<00:01,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train at epoch 50/50, loss=0.236717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training the network: 100%|█████████████████████| 50/50 [00:54<00:00,  1.09s/it]\n",
      "inference on the HSI: 6511it [01:08, 94.80it/s]                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix :\n",
      "[[ 5995     0   165     0     0     0   114   157     1]\n",
      " [    0 17718     0    28     0   343     0     1     0]\n",
      " [  196     0  1340     0     0     0     0   500     0]\n",
      " [   26    22     0  2905     0     6     0     0    13]\n",
      " [    0     0     0     0  1305     0     0     0     0]\n",
      " [    0   781     0     2    12  4079     0     4     0]\n",
      " [  188     0    43     0     0     1  1056     2     0]\n",
      " [   87    23   277     1     0     8     0  3172     3]\n",
      " [    3     0     0     2     1     0     0     0   913]]---\n",
      "Accuracy : 92.75%\n",
      "---\n",
      "class acc :\n",
      "\tAsphalt: 93.21\n",
      "\tMeadows: 97.94\n",
      "\tGravel: 65.82\n",
      "\tTrees: 97.75\n",
      "\tPainted metal sheets: 100.00\n",
      "\tBare Soil: 83.62\n",
      "\tBitumen: 81.86\n",
      "\tSelf-Blocking Bricks: 88.83\n",
      "\tShadows: 99.35\n",
      "---\n",
      "AA: 89.82%\n",
      "Kappa: 90.34\n",
      "\n",
      "FLOPs: 87971440\n",
      "Parameters: 312869\n",
      "Training time: 54.59 seconds\n",
      "Testing time: 68.75seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description=\"run patch-based HSI classification\")\n",
    "    parser.add_argument(\"--model\", type=str, default='cnn3d')\n",
    "    parser.add_argument(\"--dataset_name\", type=str, default=\"pu\")\n",
    "    parser.add_argument(\"--dataset_dir\", type=str, default=\"./datasets\")\n",
    "    parser.add_argument(\"--device\", type=str, default=\"0\")\n",
    "    parser.add_argument(\"--patch_size\", type=int, default=12)\n",
    "    parser.add_argument(\"--num_run\", type=int, default=1)\n",
    "    parser.add_argument(\"--epoch\", type=int, default=50)\n",
    "    parser.add_argument(\"--bs\", type=int, default=32)\n",
    "    parser.add_argument(\"--ratio\", type=float, default=0.03)\n",
    "\n",
    "    args, unknown = parser.parse_known_args()\n",
    "    device = torch.device(\"cuda:{}\".format(args.device) if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Print parameters\n",
    "    print(f\"experiments will run on GPU device {args.device}\")\n",
    "    print(f\"model = {args.model}\")\n",
    "    print(f\"dataset = {args.dataset_name}\")\n",
    "    print(f\"dataset folder = {args.dataset_dir}\")\n",
    "    print(f\"patch size = {args.patch_size}\")\n",
    "    print(f\"batch size = {args.bs}\")\n",
    "    print(f\"total epoch = {args.epoch}\")\n",
    "    print(f\"{args.ratio / 2} for training, {args.ratio / 2} for validation and {1 - args.ratio} for testing\")\n",
    "\n",
    "    # Load data\n",
    "    image, gt, labels = load_mat_hsi(args.dataset_name, args.dataset_dir)\n",
    "    num_classes = len(labels)\n",
    "    num_bands = image.shape[-1]\n",
    "\n",
    "    # Random seeds\n",
    "    seeds = [202201, 202202, 202203, 202204, 202205]\n",
    "\n",
    "    # Empty list to store results\n",
    "    results = []\n",
    "\n",
    "    for run in range(args.num_run):\n",
    "        np.random.seed(seeds[run])\n",
    "        print(f\"running an experiment with the {args.model} model\")\n",
    "        print(f\"run {run + 1} / {args.num_run}\")\n",
    "\n",
    "        trainval_gt, test_gt = sample_gt(gt, args.ratio, seeds[run])\n",
    "        train_gt, val_gt = sample_gt(trainval_gt, 0.5, seeds[run])\n",
    "\n",
    "        del trainval_gt\n",
    "\n",
    "        train_set = HSIDataset(image, train_gt, patch_size=args.patch_size, data_aug=True)\n",
    "        val_set = HSIDataset(image, val_gt, patch_size=args.patch_size, data_aug=False)\n",
    "        train_loader = torch.utils.data.DataLoader(train_set, batch_size=args.bs, drop_last=False, shuffle=True)\n",
    "        val_loader = torch.utils.data.DataLoader(val_set, batch_size=args.bs, drop_last=False, shuffle=False)\n",
    "\n",
    "        model = get_model(args.model, args.dataset_name, args.patch_size).to(device)\n",
    "        print(model)\n",
    "\n",
    "        if run == 0:\n",
    "            split_info_print(train_gt, val_gt, test_gt, labels)\n",
    "            print(\"network information:\")\n",
    "            # Summary of the model\n",
    "            summary(model, input_size=(1, num_bands, args.patch_size, args.patch_size))\n",
    "\n",
    "        optimizer, scheduler = load_scheduler(args.model, model)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        # Where to save checkpoint model\n",
    "        model_dir = f\"./checkpoints/{args.model}/{args.dataset_name}/{run}\"\n",
    "\n",
    "        # Training\n",
    "        start_time = time.time()\n",
    "        try:\n",
    "            train(model, optimizer, criterion, train_loader, val_loader, args.epoch, model_dir, device, scheduler)\n",
    "        except KeyboardInterrupt:\n",
    "            print('\"ctrl+c\" is pressed, the training is over')\n",
    "        training_time = time.time() - start_time\n",
    "\n",
    "        # Testing\n",
    "        start_time = time.time()\n",
    "        probabilities = test(model, model_dir, image, args.patch_size, num_classes, device)\n",
    "        testing_time = time.time() - start_time\n",
    "\n",
    "        prediction = np.argmax(probabilities, axis=-1)\n",
    "        run_results = metrics(prediction, test_gt, n_classes=num_classes)\n",
    "        results.append(run_results)\n",
    "        show_results(run_results, label_values=labels)\n",
    "\n",
    "        del train_set, train_loader, val_set, val_loader\n",
    "\n",
    "        # Calculate FLOPs and number of parameters\n",
    "        dummy_input = torch.randn(1, 1, num_bands, args.patch_size, args.patch_size).to(device)\n",
    "        flops = FlopCountAnalysis(model, dummy_input)\n",
    "        params = parameter_count(model)\n",
    "\n",
    "        print(f\"FLOPs: {flops.total()}\")\n",
    "        print(f\"Parameters: {params['']}\")\n",
    "        print(f\"Training time: {training_time:.2f} seconds\")\n",
    "        print(f\"Testing time: {testing_time:.2f}seconds\")\n",
    "\n",
    "        # Store additional metrics in results\n",
    "        run_results[\"FLOPs\"] = flops.total()\n",
    "        run_results[\"Parameters\"] = params['']\n",
    "        run_results[\"Training time\"] = training_time\n",
    "        run_results[\"Testing time\"] = testing_time\n",
    "\n",
    "    if args.num_run > 1:\n",
    "        show_results(results, label_values=labels, aggregated=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b762748-a37b-4870-8778-88d9b5b66d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6c2bbd-34f2-44e3-a94b-19cf1187c81d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
