{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07175a3-7157-4e33-8a31-eac3bd86eb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Run python -m visdom.server in the terminal before running the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "322e8da6-e093-43d1-a115-f7f00a0c3c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import cv2\n",
    "import math\n",
    "from patchify import patchify\n",
    "from sklearn.model_selection import train_test_split\n",
    "from visdom import Visdom\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import modelhsi\n",
    "from Utils import *\n",
    "import spectral\n",
    "import sys\n",
    "import argparse\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e397aee-8340-422c-b44a-60df3d09b529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add --cuda flag manually for testing\n",
    "if not sys.argv:\n",
    "    sys.argv.append(\"\")\n",
    "\n",
    "if 'ipykernel_launcher' in sys.argv[0]:\n",
    "    sys.argv = [arg for arg in sys.argv if not arg.startswith(('-f', '/'))]\n",
    "\n",
    "sys.argv.append('--cuda')\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--datasetname', default=\"SA\", help='IP,KSC,PU,SA,Houston')\n",
    "parser.add_argument('--numtrain', type=float, default=0.05, help='the number of train sets')\n",
    "parser.add_argument('--batchSize', type=int, default=32, help='batch size')\n",
    "parser.add_argument('--epochs', type=int, default=50, help='number of epochs to train for')\n",
    "parser.add_argument(\"--spectrumnum\", type=int, default=36, help=\"number of spectral after PCA\")\n",
    "parser.add_argument('--inputsize', type=int, default=11, help='size of input')\n",
    "parser.add_argument('--windowsize', type=int, default=3, help='size of windows')\n",
    "parser.add_argument(\n",
    "    \"--sampling_mode\",\n",
    "    type=str,\n",
    "    help=\"Sampling mode (random sampling or disjoint or fixed, default: random)\",\n",
    "    default=\"random\",\n",
    ")\n",
    "parser.add_argument(\"--input3D\", action=\"store_true\", default=False)\n",
    "parser.add_argument('--nz', type=int, default=50, help='size of the latent z vector')\n",
    "parser.add_argument('--D_lr', type=float, default=0.01, help='learning rate, default=0.001')\n",
    "parser.add_argument('--cuda', action='store_true', help='enables cuda')\n",
    "parser.add_argument('--netD', default='', help=\"path to netD (to continue training)\")\n",
    "parser.add_argument('--manualSeed', type=int, default=531, help='manual seed')\n",
    "parser.add_argument(\"--random_seed\", type=int, default=5, help=\"random seed\")  # Random seed\n",
    "opt = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5884962b-f36a-4ac5-8a05-a8c2fc835fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  531\n"
     ]
    }
   ],
   "source": [
    "if opt.manualSeed is None:\n",
    "    opt.manualSeed = random.randint(1, 10000)\n",
    "print(\"Random Seed: \", opt.manualSeed)\n",
    "random.seed(opt.manualSeed)\n",
    "torch.manual_seed(opt.manualSeed)\n",
    "if opt.cuda:\n",
    "    torch.cuda.manual_seed_all(opt.manualSeed)\n",
    "cudnn.benchmark = False\n",
    "\n",
    "if torch.cuda.is_available() and not opt.cuda:\n",
    "    print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7ccfbbe-56fe-4154-9ab8-fbb25d7ca08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperspectral data shape: (512, 217, 204)\n",
      "Label shape: (512, 217)\n",
      "the number of sample: 54129\n",
      "Data shape after PCA : (512, 217, 36)\n",
      "after Xtrain shape: (2706, 36, 11, 11)\n",
      "after Xtest shape: (51423, 36, 11, 11)\n",
      "label 16\n"
     ]
    }
   ],
   "source": [
    "dataset = opt.datasetname\n",
    "X, y = loadData(dataset)\n",
    "H = X.shape[0]\n",
    "W = X.shape[1]\n",
    "pca_components = opt.spectrumnum\n",
    "print('Hyperspectral data shape:', X.shape)\n",
    "print('Label shape:', y.shape)\n",
    "sample_number = np.count_nonzero(y)\n",
    "print('the number of sample:', sample_number)\n",
    "X_pca = applyPCA(X, numComponents=pca_components)\n",
    "print('Data shape after PCA :', X_pca.shape)\n",
    "[nRow, nColumn, nBand] = X_pca.shape\n",
    "num_class = int(np.max(y))\n",
    "windowsize = opt.windowsize\n",
    "Wid = opt.inputsize\n",
    "halfsizeTL = int((Wid-1)/2)\n",
    "halfsizeBR = int((Wid-1)/2)\n",
    "paddedDatax = cv2.copyMakeBorder(X_pca, halfsizeTL, halfsizeBR, halfsizeTL, halfsizeBR, cv2.BORDER_CONSTANT, 0)  #cv2.BORDER_REPLICAT周围值\n",
    "paddedDatay = cv2.copyMakeBorder(y, halfsizeTL, halfsizeBR, halfsizeTL, halfsizeBR, cv2.BORDER_CONSTANT, 0)\n",
    "patchIndex = 0\n",
    "X_patch = np.zeros((sample_number, Wid, Wid, pca_components))\n",
    "y_patch = np.zeros(sample_number)\n",
    "for h in range(0, paddedDatax.shape[0]):\n",
    "    for w in range(0, paddedDatax.shape[1]):\n",
    "        if paddedDatay[h, w] == 0:\n",
    "            continue\n",
    "        X_patch[patchIndex, :, :, :] = paddedDatax[h-halfsizeTL:h+halfsizeBR+1, w-halfsizeTL:w+halfsizeBR+1, :]\n",
    "        X_patch[patchIndex] = paddedDatay[h, w]\n",
    "        patchIndex = patchIndex + 1\n",
    "X_train_p = patchify(paddedDatax, (Wid, Wid, pca_components), step=1)\n",
    "if opt.input3D:\n",
    "    X_train_p = X_train_p.reshape(-1, Wid, Wid, pca_components, 1)\n",
    "else:\n",
    "    X_train_p = X_train_p.reshape(-1, Wid, Wid, pca_components)\n",
    "y_train_p = y.reshape(-1)\n",
    "indices_0 = np.arange(y_train_p.size)\n",
    "X_train_q = X_train_p[y_train_p > 0, :, :, :]\n",
    "y_train_q = y_train_p[y_train_p > 0]\n",
    "indices_1 = indices_0[y_train_p > 0]\n",
    "y_train_q -= 1\n",
    "X_train_q = X_train_q.transpose(0, 3, 1, 2)\n",
    "Xtrain, Xtest, ytrain, ytest, idx1, idx2 = train_test_split(X_train_q, y_train_q, indices_1,\n",
    "                                                            train_size=opt.numtrain, random_state=opt.random_seed,\n",
    "                                                            stratify=y_train_q)\n",
    "print('after Xtrain shape:', Xtrain.shape)\n",
    "print('after Xtest shape:', Xtest.shape)\n",
    "\n",
    "trainset = TrainDS(Xtrain, ytrain)\n",
    "testset = TestDS(Xtest, ytest)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=trainset, batch_size=opt.batchSize, shuffle=True, num_workers=0)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=testset, batch_size=opt.batchSize, shuffle=False, num_workers=0)\n",
    "nz = int(opt.nz)\n",
    "nc = pca_components\n",
    "nb_label = num_class\n",
    "print(\"label\", nb_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "619edac9-c819-4fd2-8e66-7101b21fe667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate total number of parameters\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# Function to calculate OA, AA, and kappa\n",
    "def calculate_metrics(C):\n",
    "    OA = np.sum(np.diag(C)) / np.sum(C)\n",
    "    AA_ACC = np.diag(C) / np.sum(C, axis=1)\n",
    "    AA = np.mean(AA_ACC)\n",
    "    pe_row = np.sum(C, axis=0)\n",
    "    pe_col = np.sum(C, axis=1)\n",
    "    pe = np.dot(pe_row, pe_col) / np.sum(C)**2\n",
    "    kappa = (OA - pe) / (1 - pe)\n",
    "    return OA, AA, kappa, AA_ACC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fbcce86-3c65-495c-86e7-1030ba3e91c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 0\n",
      "HSI_Mixer_Net(\n",
      "  (linear_projection): Linear_projection(\n",
      "    (gelu): GELU(approximate='none')\n",
      "    (conv): Conv2d(36, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (hybrid): hybrid_position_embedding(\n",
      "      (gelu): GELU(approximate='none')\n",
      "      (softmax): Softmax(dim=1)\n",
      "    )\n",
      "    (proj): Conv3d(1, 120, kernel_size=(7, 1, 1), stride=(7, 1, 1))\n",
      "  )\n",
      "  (spc_spa_mixer): Spectral_Spatial_Mixer_Block(\n",
      "    (spectral_mixer): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Residual(\n",
      "          (fn): Sequential(\n",
      "            (0): Conv3d(120, 120, kernel_size=(7, 1, 1), stride=(1, 1, 1), padding=(3, 0, 0), groups=120)\n",
      "            (1): GELU(approximate='none')\n",
      "            (2): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Conv3d(120, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "        (2): GELU(approximate='none')\n",
      "        (3): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (spatial_mixer): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Residual(\n",
      "          (fn): Sequential(\n",
      "            (0): Conv3d(120, 120, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 2, 2), dilation=(1, 2, 2), groups=120)\n",
      "            (1): GELU(approximate='none')\n",
      "            (2): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Conv3d(120, 120, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "        (2): GELU(approximate='none')\n",
      "        (3): BatchNorm3d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pool): AdaptiveAvgPool3d(output_size=(1, 1, 1))\n",
      "  (Linear): Linear(in_features=120, out_features=16, bias=True)\n",
      ")\n",
      "Total number of parameters: 39931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def train(netD, train_loader, test_loader):\n",
    "    viz = Visdom()\n",
    "    viz.close()\n",
    "\n",
    "    # Initialize accumulators for final results\n",
    "    final_acc = 0\n",
    "    final_aa = 0\n",
    "    final_kappa = 0\n",
    "    final_classwise_accuracies = None\n",
    "    \n",
    "    epoch_train_start = time.time()  # Start timing for training epoch\n",
    "    for epoch in range(1, opt.epochs + 1):\n",
    "        netD.train()\n",
    "        right = 0\n",
    "        for i, datas in enumerate(train_loader):\n",
    "            netD.zero_grad()\n",
    "            img, label = datas\n",
    "            batch_size = img.size(0)\n",
    "            input.resize_(img.size()).copy_(img)\n",
    "            c_label.resize_(batch_size).copy_(label)\n",
    "            c_output = netD(input)\n",
    "            c_errD_real = c_criterion(c_output, c_label)\n",
    "            errD_real = c_errD_real\n",
    "            errD_real.backward()\n",
    "            D_x = c_output.data.mean()\n",
    "            correct, length = test(c_output, c_label)\n",
    "            optimizerD.step()\n",
    "            right += correct\n",
    "\n",
    "        if epoch % 50 == 0:\n",
    "            netD.eval()\n",
    "            test_loss = 0\n",
    "            right = 0\n",
    "            all_Label = []\n",
    "            all_target = []\n",
    "            epoch_test_start = time.time()  # Start timing for testing epoch\n",
    "            for data, target in test_loader:\n",
    "                indx_target = target.clone()\n",
    "                if opt.cuda:\n",
    "                    data, target = data.cuda(), target.cuda()\n",
    "                with torch.no_grad():\n",
    "                    data, target = Variable(data), Variable(target)\n",
    "\n",
    "                output = netD(data)\n",
    "                test_loss += c_criterion(output, target).item()\n",
    "                pred = output.max(1)[1]  # get the index of the max log-probability\n",
    "                all_Label.extend(pred)\n",
    "                all_target.extend(target)\n",
    "                right += pred.cpu().eq(indx_target).sum()\n",
    "\n",
    "            epoch_test_end = time.time()  # End timing for testing epoch\n",
    "\n",
    "            test_loss = test_loss / len(test_loader)  # average over number of mini-batch\n",
    "            acc = float(100. * float(right)) / float(len(test_loader.dataset))\n",
    "            AAA = torch.stack(all_target).data.cpu().numpy()\n",
    "            BBB = torch.stack(all_Label).data.cpu().numpy()\n",
    "            C = confusion_matrix(AAA, BBB)\n",
    "            C = C[:num_class, :num_class]\n",
    "            k = kappa(C, np.shape(C)[0])\n",
    "            AA_ACC = np.diag(C) / np.sum(C, 1)\n",
    "            AA = np.mean(AA_ACC, 0)\n",
    "\n",
    "            # Update final accumulators\n",
    "            final_acc = acc\n",
    "            final_aa = AA\n",
    "            final_kappa = k\n",
    "            final_classwise_accuracies = AA_ACC\n",
    "\n",
    "            # Print interim progress\n",
    "            print('[%d/%d][%d/%d]   D(x): %.4f, errD_real: %.4f,  Accuracy: %.4f / %.4f = %.4f'\n",
    "                  % (epoch, opt.epochs, i, len(train_loader),\n",
    "                     D_x, errD_real,\n",
    "                     right, len(train_loader.dataset), 100. * right / len(train_loader.dataset)))\n",
    "            print('\\tTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)'.format(\n",
    "                test_loss, right, len(test_loader.dataset), acc))\n",
    "            print('OA= %.5f AA= %.5f k= %.5f' % (acc, AA, k))\n",
    "            print('Classwise Accuracies:', AA_ACC)\n",
    "            \n",
    "    epoch_train_end = time.time()  # End timing for training epoch\n",
    "    \n",
    "    # Print final results\n",
    "    print('Final OA: {:.5f}'.format(final_acc))\n",
    "    print('Final AA: {:.5f}'.format(final_aa))\n",
    "    print('Final Kappa: {:.5f}'.format(final_kappa))\n",
    "    print('Final classwise accuracies:', final_classwise_accuracies)\n",
    "    print('Training time: {:.2f} ms'.format((epoch_train_end - epoch_train_start) * 1000))\n",
    "    print('Testing time: {:.2f} ms'.format((epoch_test_end - epoch_test_start) * 1000))\n",
    "\n",
    "for index_iter in range(1):\n",
    "    print('iter:', index_iter)\n",
    "    netD = modelhsi.HSI_Mixer_Net(num_classes=num_class,\n",
    "                                img_size=Wid,\n",
    "                                patch_size=3,\n",
    "                                in_chans=pca_components,\n",
    "                                embed_dim=120\n",
    "                             )\n",
    "    if opt.netD != '':\n",
    "        netD.load_state_dict(torch.load(opt.netD))\n",
    "    print(netD)\n",
    "    \n",
    "    total_params = count_parameters(netD)\n",
    "    print(f'Total number of parameters: {total_params}')\n",
    "    \n",
    "    c_criterion = nn.CrossEntropyLoss()\n",
    "    input = torch.FloatTensor(opt.batchSize, nc, opt.inputsize, opt.inputsize)\n",
    "    c_label = torch.LongTensor(opt.batchSize)\n",
    "    if opt.cuda:\n",
    "        netD.cuda()\n",
    "        c_criterion.cuda()\n",
    "        input = input.cuda()\n",
    "        c_label = c_label.cuda()\n",
    "    input = Variable(input)\n",
    "    c_label = Variable(c_label)\n",
    "    optimizerD = optim.Adam(netD.parameters(), lr=opt.D_lr)\n",
    "    train(netD, train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d96599-26e2-47f3-bf1b-c18c149d3316",
   "metadata": {},
   "outputs": [],
   "source": [
    "### final training time = training time - testing time\n",
    "## calculate it after running the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f0e898-90c8-4181-8059-c0e0d22e2313",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
